{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "763e8d7a086c4e01af1c526a690c5c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_7de6ac44906744edb6ffad2321f833f7"
          }
        },
        "343857ddd7984b6b8952d0a5d2ff9d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f696e0442e4488d9e7d090ae4ec9587",
            "placeholder": "​",
            "style": "IPY_MODEL_c4e0e917449e402ba936190be4e65938",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "0d2b9d9bd0e541c58170705bc39aa087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_7d86d0cf268843ebb166a192071d8d2b",
            "placeholder": "​",
            "style": "IPY_MODEL_77abbedf9f3c45b9a4da7bed7b13f1ff",
            "value": ""
          }
        },
        "361065e95b1c43ee84ed8364763ff0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_f5453a3eef1e445aa358def9879dcd81",
            "style": "IPY_MODEL_2c42bd56eff64d6cbf739c8159f7df5b",
            "value": true
          }
        },
        "3d7cced5fb834fdab6bb036b1f2e476a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_1d53895b094a4935b6dcd4b8006c837d",
            "style": "IPY_MODEL_7ee1f876770445f1985f6aca1eb648d2",
            "tooltip": ""
          }
        },
        "a43a5bb0047145589267e6b5aabf23a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36994f101c9d4a5a9aa39f08df6b69f1",
            "placeholder": "​",
            "style": "IPY_MODEL_06378b5a099542c5b0fb9b3e5fecb6be",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "7de6ac44906744edb6ffad2321f833f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "8f696e0442e4488d9e7d090ae4ec9587": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4e0e917449e402ba936190be4e65938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d86d0cf268843ebb166a192071d8d2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77abbedf9f3c45b9a4da7bed7b13f1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5453a3eef1e445aa358def9879dcd81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c42bd56eff64d6cbf739c8159f7df5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d53895b094a4935b6dcd4b8006c837d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ee1f876770445f1985f6aca1eb648d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "36994f101c9d4a5a9aa39f08df6b69f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06378b5a099542c5b0fb9b3e5fecb6be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45f9db55440f4f2a86afedaebab11f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5239481624864fc1b268165f666f571d",
            "placeholder": "​",
            "style": "IPY_MODEL_04a12faa541c4b2fae5d4d0b9e35b990",
            "value": "Connecting..."
          }
        },
        "5239481624864fc1b268165f666f571d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04a12faa541c4b2fae5d4d0b9e35b990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "394dbe9844a64e6b928d34bff86737b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_761ee2e7a1f84e2680bd4375346c7eed",
              "IPY_MODEL_653c6c5e65f047f29fdc5fe4f73e0605",
              "IPY_MODEL_821c9638d1e242c7b496d091349b26e8"
            ],
            "layout": "IPY_MODEL_dfc5d1c0fd904bdcba4947b6ef8926da"
          }
        },
        "761ee2e7a1f84e2680bd4375346c7eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2b8c06053d84cd8a2d50f5be00c8713",
            "placeholder": "​",
            "style": "IPY_MODEL_75a6f3845de64beca2d36f96751dcd70",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "653c6c5e65f047f29fdc5fe4f73e0605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_078de8cbe2dc40798b0457e0f14495bc",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21a6f98a53dc41fca50c25e061c4e83e",
            "value": 4
          }
        },
        "821c9638d1e242c7b496d091349b26e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1addf59a60a450e82a08971c28838f3",
            "placeholder": "​",
            "style": "IPY_MODEL_7c866df6f6ce4b08ad321a40dd92b9b1",
            "value": " 4/4 [06:01&lt;00:00, 76.87s/it]"
          }
        },
        "dfc5d1c0fd904bdcba4947b6ef8926da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2b8c06053d84cd8a2d50f5be00c8713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75a6f3845de64beca2d36f96751dcd70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "078de8cbe2dc40798b0457e0f14495bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21a6f98a53dc41fca50c25e061c4e83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1addf59a60a450e82a08971c28838f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c866df6f6ce4b08ad321a40dd92b9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2e7e75dd9f34b2c91fb1a26d299e6ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eaa6c424a48148139cb6a7726876b81c",
              "IPY_MODEL_a8c0071384f14dbda82cecd80a5ae9f2",
              "IPY_MODEL_8f0ec62855904b8ab6616a330fe22bbe"
            ],
            "layout": "IPY_MODEL_e41a37f87a3241289d60a15692cfba10"
          }
        },
        "eaa6c424a48148139cb6a7726876b81c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32018c4c438e43adb24f81dc92e742f3",
            "placeholder": "​",
            "style": "IPY_MODEL_aed68f1539eb411eb18ec650341a05bf",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "a8c0071384f14dbda82cecd80a5ae9f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81b970c86f354be68bac1e1bba043365",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afadfad6c2724603be02c49abf2bc25b",
            "value": 100
          }
        },
        "8f0ec62855904b8ab6616a330fe22bbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26572d9aee454699925df83016d2f128",
            "placeholder": "​",
            "style": "IPY_MODEL_998830bba0244c688aae69f90e8d4d9e",
            "value": " 100/100 [00:10&lt;00:00, 11.66 examples/s]"
          }
        },
        "e41a37f87a3241289d60a15692cfba10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32018c4c438e43adb24f81dc92e742f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aed68f1539eb411eb18ec650341a05bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81b970c86f354be68bac1e1bba043365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afadfad6c2724603be02c49abf2bc25b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26572d9aee454699925df83016d2f128": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "998830bba0244c688aae69f90e8d4d9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e98f65d81bf41b9ab9631ae06f0ff1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa8490a9227c44779f8eecef58a0c72b",
              "IPY_MODEL_9271c000c4fa4af5a5a6cb9ecbf464a4",
              "IPY_MODEL_512da8e4ba834918b51c8e114454bbc6"
            ],
            "layout": "IPY_MODEL_ad4344ce90e54660ac40a8b200e7be59"
          }
        },
        "fa8490a9227c44779f8eecef58a0c72b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e277132b2ae4109b527fba5e7ac2f58",
            "placeholder": "​",
            "style": "IPY_MODEL_655653bff2ab47afbdf3014af57207c0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "9271c000c4fa4af5a5a6cb9ecbf464a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a30bcfc3a08e4db2b5df20935433c97b",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44d57d04b07e40bdb28298e029b3df7f",
            "value": 4
          }
        },
        "512da8e4ba834918b51c8e114454bbc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cadc089c59b4141ab7c6728b100c2c1",
            "placeholder": "​",
            "style": "IPY_MODEL_047a19e67c734ac0b8bfd929f0318e67",
            "value": " 4/4 [04:47&lt;00:00, 62.91s/it]"
          }
        },
        "ad4344ce90e54660ac40a8b200e7be59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e277132b2ae4109b527fba5e7ac2f58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "655653bff2ab47afbdf3014af57207c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a30bcfc3a08e4db2b5df20935433c97b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d57d04b07e40bdb28298e029b3df7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cadc089c59b4141ab7c6728b100c2c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "047a19e67c734ac0b8bfd929f0318e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Reference**:\n",
        "https://colab.research.google.com/drive/1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp?usp=sharing#scrollTo=pCqnaKmlO1U9\n",
        "\n",
        "\n",
        "**This script contains**\n",
        "\n",
        "1. finetuning of llama3.1 model: save to gdrive by default\n",
        "2. inference: abtain w2r_result.json file, save to gdrive by default\n",
        "\n",
        "**Note**\n",
        "\n",
        "Only extract waste and transformed_resource\n",
        "and add transforming_process as an empty list\n",
        "\n",
        "**Before start**\n",
        "\n",
        "- runtime change to GPU T4\n"
      ],
      "metadata": {
        "id": "9rDNjWf2NqZp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare packages and models"
      ],
      "metadata": {
        "id": "ZD2_RSwwN7Rn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMQwdFGT2O1G",
        "outputId": "93109b54-2957-47fc-c642-22cba6c0b6fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth\n",
            "  Downloading unsloth-2024.11.5-py3-none-any.whl.metadata (59 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unsloth-zoo>=2024.11.1 (from unsloth)\n",
            "  Downloading unsloth_zoo-2024.11.4-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2.5.0+cu121)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
            "  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting bitsandbytes (from unsloth)\n",
            "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting triton>=3.0.0 (from unsloth)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.1)\n",
            "Collecting tyro (from unsloth)\n",
            "  Downloading tyro-0.8.14-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting transformers>=4.46.1 (from unsloth)\n",
            "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.16.0 (from unsloth)\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.44.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.26.4)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.34.2)\n",
            "Collecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n",
            "  Downloading trl-0.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.13.2)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.24.7)\n",
            "Collecting hf-transfer (from unsloth)\n",
            "  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.16.0->unsloth)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.16.0->unsloth)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.10.10)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth) (2024.9.11)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers>=4.46.1->unsloth)\n",
            "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (13.9.3)\n",
            "Collecting torch>=2.4.0 (from unsloth)\n",
            "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.16.0->unsloth) (0.2.0)\n",
            "Downloading unsloth-2024.11.5-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.8/161.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.12.0-py3-none-any.whl (310 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.2/310.2 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2024.11.4-py3-none-any.whl (30 kB)\n",
            "Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.8.14-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, triton, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf-transfer, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, tyro, tokenizers, nvidia-cusolver-cu12, transformers, torch, xformers, datasets, bitsandbytes, trl, unsloth-zoo, unsloth\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.0+cu121\n",
            "    Uninstalling torch-2.5.0+cu121:\n",
            "      Successfully uninstalled torch-2.5.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\n",
            "torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.44.1 datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 hf-transfer-0.1.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 shtab-1.7.1 tokenizers-0.20.3 torch-2.5.1 transformers-4.46.2 triton-3.1.0 trl-0.12.0 tyro-0.8.14 unsloth-2024.11.5 unsloth-zoo-2024.11.4 xformers-0.0.28.post3 xxhash-3.5.0\n",
            "Found existing installation: unsloth 2024.11.5\n",
            "Uninstalling unsloth-2024.11.5:\n",
            "  Successfully uninstalled unsloth-2024.11.5\n",
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-3gdsxdrr/unsloth_eeef0d7815fb400f96d98f28ab5cfc52\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-3gdsxdrr/unsloth_eeef0d7815fb400f96d98f28ab5cfc52\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit 0c8c5ed81e423658ab9ae81eac5aab8d18f5d7af\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: unsloth-zoo>=2024.11.1 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.1)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.8.14)\n",
            "Requirement already satisfied: transformers>=4.46.1 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.46.2)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.44.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.24.7)\n",
            "Requirement already satisfied: hf-transfer in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.8)\n",
            "Requirement already satisfied: bitsandbytes>=0.43.3 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.44.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.20.3)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo>=2024.11.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.0)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo>=2024.11.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.34.2)\n",
            "Requirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo>=2024.11.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.12.0)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo>=2024.11.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.13.2)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.3)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\n",
            "Building wheels for collected packages: unsloth\n",
            "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unsloth: filename=unsloth-2024.11.5-py3-none-any.whl size=161007 sha256=0849052d81b7a9b2d175abae079e039050d9b46a02ed2902f6d5a1f5fb6e757e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-u21zhdds/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\n",
            "Successfully built unsloth\n",
            "Installing collected packages: unsloth\n",
            "Successfully installed unsloth-2024.11.5\n"
          ]
        }
      ],
      "source": [
        "!pip install unsloth\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes\n",
        "!pip install xformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85F5EaHZ6Gja",
        "outputId": "f5d82f99-f2be-4d99-9dfe-2ce40f52c4a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.44.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (0.0.28.post3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->xformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->xformers) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtLrfAlFbjHc",
        "outputId": "dd1b293e-eb36-4bbf-9c18-8f49d4aae27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U \"huggingface_hub[cli]\""
      ],
      "metadata": {
        "id": "mPhXz3ulcOha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db648a37-12c4-48f9-a656-2fc19cb60cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub[cli] in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Collecting huggingface_hub[cli]\n",
            "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (4.12.2)\n",
            "Collecting InquirerPy==0.3.4 (from huggingface_hub[cli])\n",
            "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface_hub[cli])\n",
            "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.48)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (2024.8.30)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.13)\n",
            "Downloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
            "Installing collected packages: pfzy, InquirerPy, huggingface_hub\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.24.7\n",
            "    Uninstalling huggingface-hub-0.24.7:\n",
            "      Successfully uninstalled huggingface-hub-0.24.7\n",
            "Successfully installed InquirerPy-0.3.4 huggingface_hub-0.26.2 pfzy-0.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "# notebook_login()\n",
        "\n",
        "# this is used to download model from huggingface"
      ],
      "metadata": {
        "id": "8JRhntamcTEF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "763e8d7a086c4e01af1c526a690c5c9d",
            "343857ddd7984b6b8952d0a5d2ff9d93",
            "0d2b9d9bd0e541c58170705bc39aa087",
            "361065e95b1c43ee84ed8364763ff0f1",
            "3d7cced5fb834fdab6bb036b1f2e476a",
            "a43a5bb0047145589267e6b5aabf23a5",
            "7de6ac44906744edb6ffad2321f833f7",
            "8f696e0442e4488d9e7d090ae4ec9587",
            "c4e0e917449e402ba936190be4e65938",
            "7d86d0cf268843ebb166a192071d8d2b",
            "77abbedf9f3c45b9a4da7bed7b13f1ff",
            "f5453a3eef1e445aa358def9879dcd81",
            "2c42bd56eff64d6cbf739c8159f7df5b",
            "1d53895b094a4935b6dcd4b8006c837d",
            "7ee1f876770445f1985f6aca1eb648d2",
            "36994f101c9d4a5a9aa39f08df6b69f1",
            "06378b5a099542c5b0fb9b3e5fecb6be",
            "45f9db55440f4f2a86afedaebab11f8f",
            "5239481624864fc1b268165f666f571d",
            "04a12faa541c4b2fae5d4d0b9e35b990"
          ]
        },
        "outputId": "e1ce5445-991c-4eb1-f782-f8dcdea4bd4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "763e8d7a086c4e01af1c526a690c5c9d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this takes around 9mins\n",
        "# model size > 16GB\n",
        "\n",
        "# !huggingface-cli download meta-llama/Meta-Llama-3.1-8B-Instruct --repo-type model --local-dir \"/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct\""
      ],
      "metadata": {
        "id": "eZbW5lNYcV_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8958e21-1b1a-43fd-faf2-a4908f102256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading '.gitattributes' to '/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/.cache/huggingface/download/.gitattributes.a6344aac8c09253b3b630fb776ae94478aa0275b.incomplete'\n",
            "\r.gitattributes:   0% 0.00/1.52k [00:00<?, ?B/s]\r.gitattributes: 100% 1.52k/1.52k [00:00<00:00, 8.89MB/s]\n",
            "Download complete. Moving file to /content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/.gitattributes\n",
            "Downloading 'LICENSE' to '/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/.cache/huggingface/download/LICENSE.a7c3ca16cee30425ed6ad841a809590f2bcbf290.incomplete'\n",
            "LICENSE: 100% 7.63k/7.63k [00:00<00:00, 40.1MB/s]\n",
            "Download complete. Moving file to /content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/LICENSE\n",
            "Downloading 'README.md' to '/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/.cache/huggingface/download/README.md.bbd5630a05b65c1a8b25141bd11ec44844107d58.incomplete'\n",
            "README.md: 100% 44.0k/44.0k [00:00<00:00, 35.3MB/s]\n",
            "Download complete. Moving file to /content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/README.md\n",
            "Downloading 'USE_POLICY.md' to '/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/.cache/huggingface/download/USE_POLICY.md.81ebb55902285e8dd5804ccf423d17ffb2a622ee.incomplete'\n",
            "USE_POLICY.md: 100% 4.69k/4.69k [00:00<00:00, 39.1MB/s]\n",
            "Download complete. Moving file to /content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/USE_POLICY.md\n",
            "Downloading 'config.json' to '/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/.cache/huggingface/download/config.json.0bb6fd75b3ad2fe988565929f329945262c2814e.incomplete'\n",
            "config.json: 100% 855/855 [00:00<00:00, 6.63MB/s]\n",
            "Download complete. Moving file to /content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/config.json\n",
            "Downloading 'generation_config.json' to '/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/.cache/huggingface/download/generation_config.json.cc7276afd599de091142c6ed3005faf8a74aa257.incomplete'\n",
            "generation_config.json: 100% 184/184 [00:00<00:00, 1.65MB/s]\n",
            "Download complete. Moving file to /content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/generation_config.json\n",
            "Downloading 'model-00001-of-00004.safetensors' to '/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/.cache/huggingface/download/model-00001-of-00004.safetensors.2b1879f356aed350030bb40eb45ad362c89d9891096f79a3ab323d3ba5607668.incomplete'\n",
            "model-00001-of-00004.safetensors: 100% 4.98G/4.98G [01:29<00:00, 55.7MB/s]\n",
            "Download complete. Moving file to /content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/model-00001-of-00004.safetensors\n",
            "Downloading 'model-00002-of-00004.safetensors' to '/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/.cache/huggingface/download/model-00002-of-00004.safetensors.09d433f650646834a83c580877bd60c6d1f88f7755305c12576b5c7058f9af15.incomplete'\n",
            "model-00002-of-00004.safetensors: 100% 5.00G/5.00G [01:38<00:00, 50.7MB/s]\n",
            "Download complete. Moving file to /content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/model-00002-of-00004.safetensors\n",
            "Downloading 'model-00003-of-00004.safetensors' to '/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/.cache/huggingface/download/model-00003-of-00004.safetensors.fc1cdddd6bfa91128d6e94ee73d0ce62bfcdb7af29e978ddcab30c66ae9ea7fa.incomplete'\n",
            "model-00003-of-00004.safetensors: 100% 4.92G/4.92G [01:46<00:00, 46.0MB/s]\n",
            "Download complete. Moving file to /content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/model-00003-of-00004.safetensors\n",
            "Downloading 'model-00004-of-00004.safetensors' to '/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/.cache/huggingface/download/model-00004-of-00004.safetensors.92ecfe1a2414458b4821ac8c13cf8cb70aed66b5eea8dc5ad9eeb4ff309d6d7b.incomplete'\n",
            "model-00004-of-00004.safetensors: 100% 1.17G/1.17G [00:21<00:00, 55.2MB/s]\n",
            "Download complete. Moving file to /content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/model-00004-of-00004.safetensors\n",
            "Downloading 'model.safetensors.index.json' to '/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/.cache/huggingface/download/model.safetensors.index.json.0fd8120f1c6acddc268ebc2583058efaf699a771.incomplete'\n",
            "model.safetensors.index.json: 100% 23.9k/23.9k [00:00<00:00, 86.4MB/s]\n",
            "Download complete. Moving file to /content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/model.safetensors.index.json\n",
            "Downloading 'original/consolidated.00.pth' to '/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/.cache/huggingface/download/original/consolidated.00.pth.ab33d910f405204e5d388bc3521503584800461dc96808e287821dd451c1edac.incomplete'\n",
            "consolidated.00.pth: 100% 16.1G/16.1G [04:59<00:00, 53.6MB/s]\n",
            "Download complete. Moving file to /content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/original/consolidated.00.pth\n",
            "Downloading 'original/params.json' to '/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/.cache/huggingface/download/original/params.json.f1131204e79d0c09d2bac93f11569a8a655d68ba.incomplete'\n",
            "original/params.json: 100% 199/199 [00:00<00:00, 634kB/s]\n",
            "Download complete. Moving file to /content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/original/params.json\n",
            "Downloading 'original/tokenizer.model' to '/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/.cache/huggingface/download/original/tokenizer.model.82e9d31979e92ab929cd544440f129d9ecd797b69e327f80f17e1c50d5551b55.incomplete'\n",
            "tokenizer.model: 100% 2.18M/2.18M [00:00<00:00, 6.37MB/s]\n",
            "Download complete. Moving file to /content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/original/tokenizer.model\n",
            "Downloading 'special_tokens_map.json' to '/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/.cache/huggingface/download/special_tokens_map.json.02ee80b6196926a5ad790a004d9efd6ab1ba6542.incomplete'\n",
            "special_tokens_map.json: 100% 296/296 [00:00<00:00, 1.26MB/s]\n",
            "Download complete. Moving file to /content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/special_tokens_map.json\n",
            "Downloading 'tokenizer.json' to '/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/.cache/huggingface/download/tokenizer.json.5cc5f00a5b203e90a27a3bd60d1ec393b07971e8.incomplete'\n",
            "tokenizer.json: 100% 9.09M/9.09M [00:10<00:00, 879kB/s]\n",
            "Download complete. Moving file to /content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/tokenizer.json\n",
            "Downloading 'tokenizer_config.json' to '/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/.cache/huggingface/download/tokenizer_config.json.db88166e2bc4c799fd5d1ae643b75e84d03ee70e.incomplete'\n",
            "tokenizer_config.json: 100% 55.4k/55.4k [00:00<00:00, 3.63MB/s]\n",
            "Download complete. Moving file to /content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct/tokenizer_config.json\n",
            "/content/drive/MyDrive/Colab Notebooks/W2R/Meta-Llama-3.1-8B-Instruct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "orig_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"/content/drive/MyDrive/Colab Notebooks/W2R//Meta-Llama-3.1-8B-Instruct\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "394dbe9844a64e6b928d34bff86737b8",
            "761ee2e7a1f84e2680bd4375346c7eed",
            "653c6c5e65f047f29fdc5fe4f73e0605",
            "821c9638d1e242c7b496d091349b26e8",
            "dfc5d1c0fd904bdcba4947b6ef8926da",
            "f2b8c06053d84cd8a2d50f5be00c8713",
            "75a6f3845de64beca2d36f96751dcd70",
            "078de8cbe2dc40798b0457e0f14495bc",
            "21a6f98a53dc41fca50c25e061c4e83e",
            "a1addf59a60a450e82a08971c28838f3",
            "7c866df6f6ce4b08ad321a40dd92b9b1"
          ]
        },
        "id": "A7dI8CPk3gJx",
        "outputId": "bc83b59c-1312-45f7-b0c1-3bbbe3289543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "==((====))==  Unsloth 2024.11.5: Fast Llama patching. Transformers = 4.46.2.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.5.1+cu124. CUDA = 7.5. CUDA Toolkit = 12.4.\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "394dbe9844a64e6b928d34bff86737b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/W2R//Meta-Llama-3.1-8B-Instruct does not have a padding token! Will use pad_token = <|finetune_right_pad_id|>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference - test initial performance"
      ],
      "metadata": {
        "id": "So0aSl6vfTt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "IpLcPnUfgTmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FastLanguageModel.for_inference(orig_model) # Enable native 2x faster inference"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiQsM8K-g4vY",
        "outputId": "10538afc-c938-4859-a73e-8a107d6968e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(128256, 4096)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaAttention(\n",
              "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Requirments:\n",
        "- Perform extraction by yourself and only assign the results to the corresponding keys.\n",
        "- Extract only names or phrases that describe wastes and transformed resources.\n",
        "- If no wastes or resources are found, keep the corresponding list empty.\n",
        "- Do not include any explanations or comments; do not import any libraries; output only the additional code needed to perform the extraction.\n",
        "\n"
      ],
      "metadata": {
        "id": "NSbiEQUoDTUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_instruction_from_abstract():\n",
        "    instruction_template = \"\"\"Complete the code by extracting the waste-to-resource information from the given paragraph.\n",
        "You should extract related waste and transformed resources as lists and assign them under keys of \"waste\" and \"tranformed_resource\", respectively.\n",
        "Do not import libraries. Do not use abbreviations. Do not explain yourself. Directly output the newly added code. \"\"\"\n",
        "    return instruction_template\n",
        "\n",
        "def make_coded_abstract(abstract):\n",
        "  coded_abstract = \"\"\"\n",
        "```python\n",
        "def extract():\n",
        "  text = \"{abstract}\"\n",
        "  w2r = {{\"waste\": [], \"transformed_resource\": []}}\n",
        "  # now read the text, assign wastes and resources lists to w2r keys\n",
        "  # directly output the newly added code\n",
        "```\"\"\".format(abstract=abstract)\n",
        "  return coded_abstract\n",
        "\n",
        "def make_formatted_prompt(abstract)-> str:\n",
        "  instruction = make_instruction_from_abstract()\n",
        "  input_x = make_coded_abstract(abstract)\n",
        "\n",
        "  llama31_prompt=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "{}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
        "\n",
        "  formatted_prompt = llama31_prompt.format(instruction, input_x)\n",
        "  return formatted_prompt\n"
      ],
      "metadata": {
        "id": "bEDZ7KFhfWLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test one example"
      ],
      "metadata": {
        "id": "zHfi7r8jhJLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextIteratorStreamer\n",
        "\n",
        "abstract = \"The pyrolysis and co-pyrolysis characteristics of large abundant bio-wastes, namely date pits (DP), peanut shells (PS), coffee grounds (CG), and tea waste (TW) were investigated in detail. The TG/DTG and pyrolysis procedures were used to examine the thermal pyrolysis behavior of these agro-wastes and their blends (50%CG/50%DP, 50%CG/50%PS, 50%DP/50%PS, 50%TW/50% DP,50%TW/50%PS and 50%CG/50% TW by weight). The characterization of these feedstock has shown their suitability for energy and material valorization. Experiments were carried out in a batch pyrolysis at a medium heating rate of 10 °C/min. The goal was to identify the best combination aiming to produce either char or hydrogen-rich gas, which can contribute to the development of the circular bio-economy. It was demonstrated that pyrolysis favored the liquid product, fluctuating from 34.31% (TW) to 50.92% (DP), while the co-pyrolysis greatly increased the gaseous product, which ranged between 42.02% (TW-DP) and 55.17% (PS-TW). The blending of CG and PS resulted in heightened reactivity, leading to an enhanced generation of H2 (34.44%). The optimal mixture was found to be CG-TW, showcasing superior performance in terms of gas quality (38.39% H2) and yield (53.74%). This outcome underscores the potential of CG and TW as a synergistic blend for efficient hydrogen-rich gas production. The FTIR findings revealed that the recovered biochars have the potential to serve as solid fuels, biofertilizers, or carbon materials. Additionally, they could be used as eco-friendly precursors for chemical and related industries. By analyzing various waste mixtures and their respective pyrolysis properties, this research aims to contribute to the development of sustainable waste management practices as well as efficient energy and material production methods. © 2024 The Institution of Chemical Engineers\"\n",
        "inputs_string = make_formatted_prompt(abstract)\n",
        "\n",
        "inputs = tokenizer([inputs_string], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Initialize the TextIteratorStreamer\n",
        "text_iter_streamer = TextIteratorStreamer(tokenizer)\n",
        "\n",
        "# Generate the content using the model and the streamer\n",
        "_ = orig_model.generate(**inputs, streamer=text_iter_streamer, max_new_tokens=1024)\n",
        "\n",
        "# Collect the generated tokens from the streamer and join them into a single string\n",
        "generated_text = \"\".join([token for token in text_iter_streamer])\n",
        "\n",
        "# Remove the original input part from the generated text, if needed\n",
        "original_input_text = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)\n",
        "generated_text = generated_text[len(original_input_text):].strip()\n",
        "\n",
        "# Print or use the generated content\n",
        "print(\"Result: \")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6ZegVuXfV1v",
        "outputId": "b21008c6-3b2f-4ff8-ac5f-1de795a380b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: \n",
            "w read the text, assign wastes and resources lists to w2r keys\n",
            "  # directly output the newly added code\n",
            "```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "```python\n",
            "def extract():\n",
            "  text = \"The pyrolysis and co-pyrolysis characteristics of large abundant bio-wastes, namely date pits (DP), peanut shells (PS), coffee grounds (CG), and tea waste (TW) were investigated in detail. The TG/DTG and pyrolysis procedures were used to examine the thermal pyrolysis behavior of these agro-wastes and their blends (50%CG/50%DP, 50%CG/50%PS, 50%DP/50%PS, 50%TW/50% DP,50%TW/50%PS and 50%CG/50% TW by weight). The characterization of these feedstock has shown their suitability for energy and material valorization. Experiments were carried out in a batch pyrolysis at a medium heating rate of 10 °C/min. The goal was to identify the best combination aiming to produce either char or hydrogen-rich gas, which can contribute to the development of the circular bio-economy. It was demonstrated that pyrolysis favored the liquid product, fluctuating from 34.31% (TW) to 50.92% (DP), while the co-pyrolysis greatly increased the gaseous product, which ranged between 42.02% (TW-DP) and 55.17% (PS-TW). The blending of CG and PS resulted in heightened reactivity, leading to an enhanced generation of H2 (34.44%). The optimal mixture was found to be CG-TW, showcasing superior performance in terms of gas quality (38.39% H2) and yield (53.74%). This outcome underscores the potential of CG and TW as a synergistic blend for efficient hydrogen-rich gas production. The FTIR findings revealed that the recovered biochars have the potential to serve as solid fuels, biofertilizers, or carbon materials. Additionally, they could be used as eco-friendly precursors for chemical and related industries. By analyzing various waste mixtures and their respective pyrolysis properties, this research aims to contribute to the development of sustainable waste management practices as well as efficient energy and material production methods. 2024 The Institution of Chemical Engineers\"\n",
            "  w2r = {\"waste\": [], \"transformed_resource\": []}\n",
            "  w2r[\"waste\"] = [\"date pits (DP)\", \"peanut shells (PS)\", \"coffee grounds (CG)\", \"tea waste (TW)\"]\n",
            "  w2r[\"transformed_resource\"] = [\"char\", \"hydrogen-rich gas\", \"liquid product\", \"biofertilizers\", \"carbon materials\", \"solid fuels\", \"eco-friendly precursors for chemical and related industries\"]\n",
            "  return w2r\n",
            "\n",
            "print(extract())\n",
            "```<|eot_id|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "run on test abstracts and save result"
      ],
      "metadata": {
        "id": "EEikKfcbiF2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "import json\n",
        "import time\n",
        "import ast\n",
        "import re"
      ],
      "metadata": {
        "id": "OT2gBMf4hLw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract(abstract):\n",
        "  inputs_string = make_formatted_prompt(abstract)\n",
        "  inputs = tokenizer([inputs_string], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "  # Initialize the TextIteratorStreamer\n",
        "  text_iter_streamer = TextIteratorStreamer(tokenizer)\n",
        "\n",
        "  # generate\n",
        "  _ = orig_model.generate(**inputs, streamer=text_iter_streamer, max_new_tokens=1024)\n",
        "  generated_text = \"\".join([token for token in text_iter_streamer])\n",
        "\n",
        "  # Remove the original input part from the generated text, if needed\n",
        "  original_input_text = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)\n",
        "  generated_text = generated_text[len(original_input_text):].strip()\n",
        "\n",
        "  return generated_text\n",
        "\n",
        "\n",
        "def extract_postprocessing(result):\n",
        "  w2r = {\"waste\": [], \"transforming_process\": [], \"transformed_resource\": []}\n",
        "  try:\n",
        "    # Regular expression pattern to match w2r assignments\n",
        "    pattern = r'w2r\\[\"(?P<key>\\w+)\"\\]\\s*=\\s*(?P<value>\\[.*?\\])'\n",
        "    # pattern = r'(?:w2r\\[\"(?P<key>\\w+)\"\\]|(?P<key>\\w+))\\s*=\\s*(?P<value>\\[.*?\\])'\n",
        "    # Find all matches in the code string\n",
        "    matches = re.finditer(pattern, result, re.DOTALL)\n",
        "    for match in matches:\n",
        "      key = match.group('key')\n",
        "      value_str = match.group('value')\n",
        "      try:\n",
        "        # Safely evaluate the list using ast.literal_eval\n",
        "        value = ast.literal_eval(value_str)\n",
        "        if isinstance(value, list):\n",
        "          w2r[key] = value\n",
        "        else:\n",
        "          print(f\"Warning: The value for '{key}' is not a list.\")\n",
        "      except Exception as e:\n",
        "        print(f\"Error evaluating the list for '{key}': {e}\")\n",
        "  except Exception as e:\n",
        "    print(\"An error occurred while parsing the code string:\", e)\n",
        "  return w2r\n",
        "\n",
        "\n",
        "def check_make_dir(directory, exist_ok=False):\n",
        "  if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "    return directory\n",
        "  else:\n",
        "    if not exist_ok:\n",
        "      i = 1\n",
        "      # increment until finding an available name\n",
        "      new_dir = f\"{directory}_{i}\"\n",
        "      while os.path.exists(new_dir):\n",
        "        i += 1\n",
        "        new_dir = f\"{directory}_{i}\"\n",
        "      os.makedirs(new_dir)\n",
        "      return new_dir\n",
        "    return directory"
      ],
      "metadata": {
        "id": "yEEQlzI0hLoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_abstracts(args):\n",
        "\n",
        "  # num, model, prompt, save_dir, shot_length, shot_k\n",
        "\n",
        "  result_json_file = os.path.join(args.save_dir, \"w2r_results.json\")\n",
        "  result_invalid_file = os.path.join(args.save_dir, \"w2r_invalid.txt\")\n",
        "  result_invalid_doi_file = os.path.join(args.save_dir, \"w2r_invalid_doi.txt\")\n",
        "\n",
        "  df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/W2R/scopus_waste2resource.csv\")\n",
        "  abstract_list = df[\"Abstract\"].tolist()\n",
        "  doi_list = df[\"DOI\"].tolist()\n",
        "\n",
        "  if args.start_index:\n",
        "    abstract_list = abstract_list[args.start_index:]\n",
        "    doi_list = doi_list[args.start_index:]\n",
        "\n",
        "  if args.num > 0:\n",
        "    abstract_list = abstract_list[:args.num]\n",
        "    doi_list = doi_list[:args.num]\n",
        "\n",
        "  result_json_list = []\n",
        "  result_invalid_str = \"\"\n",
        "  result_invalid_doi_list = []\n",
        "\n",
        "  total_time = 0\n",
        "\n",
        "  for i, abstract in enumerate(abstract_list):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # get llm output and process\n",
        "    coded_abstract = abstract   # no need to wrap\n",
        "    result_str = extract(coded_abstract)\n",
        "    result_json = extract_postprocessing(result_str)\n",
        "\n",
        "    # add the referece and append\n",
        "    result_json[\"reference\"] = doi_list[i]\n",
        "    result_json_list.append(result_json)\n",
        "\n",
        "    # check if the extracted information is valid\n",
        "    if len(result_json[\"waste\"]) == 0 and len(result_json[\"transforming_process\"]) == 0 and len(result_json[\"transformed_resource\"]) == 0:\n",
        "      result_invalid_str += result_str + \"\\n\\n----------\\n\\n\"\n",
        "      result_invalid_doi_list.append(doi_list[i])\n",
        "\n",
        "    logging.info(\"----------------------------------\")\n",
        "    logging.info(\"Processing abstract {}\".format(i))\n",
        "    logging.info(\"Coded abstract: \\n{}\".format(coded_abstract))\n",
        "    logging.info(\"LLM response: \\n{}\".format(result_str))\n",
        "    logging.info(\"Extracted w2r: \\n{}\".format(result_json))\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time += end_time - start_time\n",
        "    logging.info(\"Time taken: {:.2f} seconds\".format(end_time - start_time))\n",
        "    print(\"Processing abstract {}, time taken: {:.2f} seconds\".format(i, end_time - start_time))\n",
        "    # end for loop\n",
        "\n",
        "    # save results each 10 abstracts\n",
        "    if i % 5 == 0:\n",
        "      with open(result_json_file, 'w') as file:\n",
        "        json.dump(result_json_list, file, indent=4)\n",
        "\n",
        "  # save the final result\n",
        "  with open(result_json_file, 'w') as file:\n",
        "    json.dump(result_json_list, file, indent=4)\n",
        "\n",
        "  try:\n",
        "    with open(result_invalid_file, 'w') as file:\n",
        "      file.write(result_invalid_str)\n",
        "  except:\n",
        "    with open(result_invalid_file, 'w', encoding='utf-8') as file:\n",
        "      file.write(result_invalid_str)\n",
        "\n",
        "  with open(result_invalid_doi_file, 'w') as file:\n",
        "    for invalid_doi in result_invalid_doi_list:   # if empty, doi = nan, then need to convert to string\n",
        "      file.write(str(invalid_doi) + '\\n')\n",
        "\n",
        "  logging.info(\"-------------\"*5)\n",
        "  logging.info(\"Successfully extracted: {} / {}\".format(len(result_json_list), len(abstract_list)))\n",
        "  logging.info(\"Total time: {}, averaged time: {} seconds\".format(total_time, total_time/len(result_json_list)))\n"
      ],
      "metadata": {
        "id": "yzc2qk6mhLfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "  def __init__(self):\n",
        "    self.num = 50\n",
        "    self.start_index = None\n",
        "    self.save_dir = \"/content/drive/MyDrive/Colab Notebooks/W2R/extraction_finetune_unsloth/result_codestyle_basic\"\n",
        "    self.save_dir_rewrite = True\n",
        "    self.repeat = 5\n",
        "\n",
        "# Create an instance of Args\n",
        "args = Args()\n",
        "base_folder = args.save_dir\n",
        "\n",
        "# Run the process_abstracts function\n",
        "for i in range(args.repeat):\n",
        "  print(\"Running experiment {}/{}\".format(i+1, args.repeat))\n",
        "  logging.info(\"Running experiment {}/{}\".format(i+1, args.repeat))\n",
        "\n",
        "\n",
        "  # create subfolder in the save_dir: run_{i}\n",
        "  save_dir = os.path.join(base_folder, \"run_{}\".format(i))\n",
        "  args.save_dir = check_make_dir(save_dir, exist_ok=args.save_dir_rewrite)\n",
        "\n",
        "  # set logging file\n",
        "  logger = logging.getLogger()\n",
        "  if logger.hasHandlers():\n",
        "    logger.handlers.clear()\n",
        "  log_file = os.path.join(args.save_dir, \"extraction_log.log\")\n",
        "  logging.basicConfig(filename=log_file, filemode='w', level=logging.INFO, format='%(message)s')\n",
        "\n",
        "  # Log each argument and its value\n",
        "  for arg, value in vars(args).items():\n",
        "    logging.info(f'Argument {arg}: {value}')\n",
        "    print(f'{arg}: {value}')\n",
        "  logging.info(\"-------------\"*5)\n",
        "\n",
        "  process_abstracts(args)"
      ],
      "metadata": {
        "id": "tdj4ETJti1DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HlzVh7bIi08o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cuP_kLeLi00i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetune model"
      ],
      "metadata": {
        "id": "DtJypUqYgNjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model = orig_model,\n",
        "    r = 8,   # higher r allow model to learn more parameters\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\",   # query, key, value projections in the attention layers\n",
        "                      \"o_proj\",      # output projection of the attention\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\"],  # related to gating mechanisms within the model\n",
        "    lora_alpha = 32,   # control how much the learned low-rank matrics affect the original weights\n",
        "    lora_dropout = 0.2,\n",
        "    bias = \"none\",    # none / all / lora_only\n",
        "    use_gradient_checkpointing = \"unsloth\",  # unsloth / True. unsloth reduce VRAM by 30%\n",
        "    random_state = 55,\n",
        "    use_rslora = False,    # rank stablised LoRA\n",
        "    loftq_config = None,   # LoftQ: low-rank and fine-tuned quantizatioin\n",
        ")"
      ],
      "metadata": {
        "id": "DswU--Y68XlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08f3f553-52c4-4146-a4c2-9b662f5ac311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.2.\n",
            "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
            "Unsloth 2024.11.5 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preparation"
      ],
      "metadata": {
        "id": "neFEkCcL-oPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "wwzIp2zcESWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def make_instruction_from_abstract():\n",
        "    instruction_template = \"\"\"Complete the code by extracting the waste-to-resource information from the given paragraph.\n",
        "You should extract related waste and transformed resources as lists and assign them under keys of \"waste\" and \"tranformed_resource\", respectively.\n",
        "Directly output the complete code. Do not import libraries. Do not use abbreviations. Do not explain yourself.\"\"\"\n",
        "    return instruction_template\n",
        "\n",
        "def make_coded_abstract(abstract):\n",
        "  coded_abstract = \"\"\"\n",
        "```python\n",
        "def extract():\n",
        "  text = \"{abstract}\"\n",
        "  w2r = {{\"waste\": [], \"transformed_resource\": []}}\n",
        "  # now read the text, assign wastes and resources lists to w2r keys\n",
        "```\"\"\".format(abstract=abstract)\n",
        "  return coded_abstract\n",
        "\n",
        "def make_coded_result(result):\n",
        "  coded_result = \"\"\"\n",
        "```python\n",
        "w2r[\"waste\"] = {}\n",
        "w2r[\"transformed_resource\"] = {}\n",
        "```\n",
        "\"\"\".format(json.dumps(result[\"waste\"]), json.dumps(result[\"transformed_resource\"]))\n",
        "  return coded_result\n",
        "\n",
        "def make_formatted_prompt(abstract, result)-> str:\n",
        "  instruction = make_instruction_from_abstract()\n",
        "  input_x = make_coded_abstract(abstract)\n",
        "  result_str = make_coded_result(result)\n",
        "\n",
        "  llama31_prompt=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "{}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "{}<|eot_id|>\"\"\"\n",
        "\n",
        "  formatted_prompt = llama31_prompt.format(instruction, input_x, result_str)\n",
        "  return formatted_prompt"
      ],
      "metadata": {
        "id": "eqt1YM5xk8Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "EOS_TOKEN = tokenizer.eos_token  # must add this, otherwise the generation will not stop\n",
        "\n",
        "def prepare_dataset(annotation_file):\n",
        "  with open(annotation_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "  # format\n",
        "  formatted_data = []\n",
        "  for entry in data:\n",
        "    abstract = entry[\"abstract\"]\n",
        "    result = {\"waste\": entry[\"waste\"], \"transformed_resource\": entry[\"transformed_resource\"]}\n",
        "\n",
        "    text = make_formatted_prompt(abstract, result) + EOS_TOKEN  # MAYBE DON'T NEED EOS_TOKEN\n",
        "    formatted_data.append({\"text\":text})\n",
        "\n",
        "  dataset = Dataset.from_list(formatted_data)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "ZDfNGzTT-qWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# annotation_file = \"/content/finetune_dataset.json\"\n",
        "annotation_file = \"/content/drive/MyDrive/Colab Notebooks/W2R/extraction_finetune_dataset.json\"\n",
        "with open(annotation_file, \"r\", encoding=\"utf-8\") as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "train_data = prepare_dataset(annotation_file)"
      ],
      "metadata": {
        "id": "mOZAnS_UjZut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eniNYu8YNfoL",
        "outputId": "d43a5179-684d-413d-935d-0b1e1b5203d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nComplete the code by extracting the waste-to-resource information from the given paragraph.\\nYou should extract related waste and transformed resources as lists and assign them under keys of \"waste\" and \"tranformed_resource\", respectively.\\nDirectly output the complete code. Do not import libraries. Do not use abbreviations. Do not explain yourself.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n\\n```python\\ndef extract():\\n  text = \"Extracting functional materials from industrial waste residues to absorb organic dyes can maximize waste reuse and minimize water pollution. However, the extraordinarily low purification efficiency still limits the practical application of this strategy. Herein, the lamellar NiOOH is in-situ anchored on the industrial waste red mud surface (ARM/NiOOH) as an adsorbent to purify organic dyes in wastewater. ARM/NiOOH adsorbent with high specific surface area and porosity provides considerable active sites for the congo red (CR), thereby significantly enhancing the removal efficiency of CR. Besides, we fit a reasonable adsorption model for ARM/NiOOH adsorbent and investigate its adsorption kinetics. Resultantly, ARM/NiOOH adsorbent can remarkably adsorb 348.0 mg g−1 CR within 5 min, which is 7.91 times that of raw RM. Our work provides a strategy for reusing industrial waste and purifying sewage pollution, which advances wastewater treatment engineering. © 2024 The Author(s)\"\\n  w2r = {\"waste\": [], \"transformed_resource\": []}\\n  # now read the text, assign wastes and resources lists to w2r keys\\n```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\\n```python\\nw2r[\"waste\"] = [\"industrial waste red mud\"]\\nw2r[\"transformed_resource\"] = [\"adsorbent\", \"wastewater purification\"]\\n```\\n<|eot_id|><|eot_id|>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-KVjfowOHya",
        "outputId": "68c9fcbb-2fae-4277-8ab5-403ffee7352c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model and save to GDrive"
      ],
      "metadata": {
        "id": "Rqzo9YyDNm_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported   # check if hardware supports bfloat16 precision\n",
        "import time\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = train_data,\n",
        "    dataset_text_field = \"text\",     # formatted_data.append({\"text\":text})\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,  # num of processes for dataset preprocessing, which speeds up data preparation\n",
        "    packing = False,  # if True, combine shorter sequences to fill each batch, can increase training speed\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        num_train_epochs = 10, # set this for 1 full training run,\n",
        "        # max_steps = 60,     # otherwise, set maximum number of training steps\n",
        "        learning_rate = 1e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 55,\n",
        "        output_dir = \"output\",\n",
        "        report_to = \"none\",  # can export to services like Weights & Biases or TensorBoard\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f2e7e75dd9f34b2c91fb1a26d299e6ef",
            "eaa6c424a48148139cb6a7726876b81c",
            "a8c0071384f14dbda82cecd80a5ae9f2",
            "8f0ec62855904b8ab6616a330fe22bbe",
            "e41a37f87a3241289d60a15692cfba10",
            "32018c4c438e43adb24f81dc92e742f3",
            "aed68f1539eb411eb18ec650341a05bf",
            "81b970c86f354be68bac1e1bba043365",
            "afadfad6c2724603be02c49abf2bc25b",
            "26572d9aee454699925df83016d2f128",
            "998830bba0244c688aae69f90e8d4d9e"
          ]
        },
        "id": "L0jh2mGeNmK1",
        "outputId": "d5126993-352a-4028-987a-fbc5012b2d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2e7e75dd9f34b2c91fb1a26d299e6ef"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHwPyN_oQpmq",
        "outputId": "dae2fa57-4d4f-411f-89b5-f9c129fc0f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.748 GB.\n",
            "5.984 GB of memory reserved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "Jr6sGYCb09zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"finetuned_model_codestyle4\"\n",
        "base_dir = \"/content/drive/MyDrive/Colab Notebooks/W2R/extraction_finetune_unsloth\"   # save to Gdrive\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "trainer_stats = trainer.train()\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training time: {(end_time - start_time)/60} minutes\")\n",
        "\n",
        "\n",
        "model.save_pretrained(os.path.join(base_dir, model_name))\n",
        "tokenizer.save_pretrained(os.path.join(base_dir, model_name))\n",
        "print(\"Finetuned model saved at: \", os.path.join(base_dir, model_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_JaXs_sISwgp",
        "outputId": "5116c10e-961f-4320-887a-5810c796361e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 100 | Num Epochs = 10\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 120\n",
            " \"-____-\"     Number of trainable parameters = 20,971,520\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 24:28, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.708500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.847700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.624500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.477500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.440400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.323200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.013500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.091300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.825400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.853900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.912200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.623100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>2.476000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.431600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.341200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.788500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.288600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.341000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.346300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.297600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.398900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.391500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.377400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.543600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.287300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.431600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.208600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.362000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.323300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.443800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.216800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.408600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.370500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.159600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.342600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.168300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.884200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.227000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.306200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.378600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.049600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.148100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.480600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.018400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.368100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.312700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.157700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.605900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.212700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.250500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.050500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.963200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.167900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.101600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.973500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.044100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1.236600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.068700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>1.174700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>1.109300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>1.568800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>1.094600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.922800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.849000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.868200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>1.103500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.880100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.128100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>1.021500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.782800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>1.012800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.951900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.440900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.878900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.738200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.818200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.874400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.834800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.840400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.767800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.867300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.845900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.872500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.925400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.854700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>1.306800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.847200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.666900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.740400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.732400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.783800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.768700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.735500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.584800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.779600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.572300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.735900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.018800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>0.704700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>0.610100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>0.739400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>0.676800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>0.537700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>0.506000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>0.563100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>0.685200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>0.736100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.716500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>0.621700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>0.589200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>0.920200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>0.511700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.632400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>0.524500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>0.742000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>0.583800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>0.574100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.631400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 25.03040300210317 minutes\n",
            "Finetuned model saved at:  /content/drive/MyDrive/Colab Notebooks/W2R/extraction_finetune_unsloth/finetuned_model_codestyle4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory         /max_memory*100, 3)\n",
        "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHBgbsuEWEqB",
        "outputId": "edbca8a8-8edb-4c9d-ba75-a20efd86048d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1494.8971 seconds used for training.\n",
            "24.91 minutes used for training.\n",
            "Peak reserved memory = 7.982 GB.\n",
            "Peak reserved memory for training = 1.998 GB.\n",
            "Peak reserved memory % of max memory = 54.123 %.\n",
            "Peak reserved memory for training % of max memory = 13.548 %.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "fEY5Fe_3Woyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**load fine-tuned model**"
      ],
      "metadata": {
        "id": "fhctERpyWqkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True"
      ],
      "metadata": {
        "id": "a-NvRVapyTXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import os\n",
        "\n",
        "model_name = \"finetuned_model_codestyle3\"\n",
        "base_dir = \"/content/drive/MyDrive/Colab Notebooks/W2R/extraction_finetune_unsloth\"   # save to Gdrive\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = os.path.join(base_dir, model_name), # MODEL NAME here\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")\n"
      ],
      "metadata": {
        "id": "K_K2lDaOWoEE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175,
          "referenced_widgets": [
            "4e98f65d81bf41b9ab9631ae06f0ff1a",
            "fa8490a9227c44779f8eecef58a0c72b",
            "9271c000c4fa4af5a5a6cb9ecbf464a4",
            "512da8e4ba834918b51c8e114454bbc6",
            "ad4344ce90e54660ac40a8b200e7be59",
            "8e277132b2ae4109b527fba5e7ac2f58",
            "655653bff2ab47afbdf3014af57207c0",
            "a30bcfc3a08e4db2b5df20935433c97b",
            "44d57d04b07e40bdb28298e029b3df7f",
            "5cadc089c59b4141ab7c6728b100c2c1",
            "047a19e67c734ac0b8bfd929f0318e67"
          ]
        },
        "outputId": "95910959-49a6-45b4-ffcd-a6dbbf5ff3a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2024.11.5: Fast Llama patching. Transformers = 4.46.2.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.5.1+cu124. CUDA = 7.5. CUDA Toolkit = 12.4.\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e98f65d81bf41b9ab9631ae06f0ff1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2024.11.5 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6xSn6VVFJdV",
        "outputId": "ae420375-e328-442b-8b05-d22c503555fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(128256, 4096, padding_idx=128004)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaExtendedRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=14336, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_instruction_from_abstract():\n",
        "    instruction_template = \"\"\"Complete the code by extracting the waste-to-resource information from the given paragraph.\n",
        "You should extract related waste and transformed resources as lists and assign them under keys of \"waste\" and \"tranformed_resource\", respectively.\n",
        "Do not import libraries. Do not use abbreviations. Do not explain yourself. Directly output the newly added code. \"\"\"\n",
        "    return instruction_template\n",
        "\n",
        "def make_coded_abstract(abstract):\n",
        "  coded_abstract = \"\"\"\n",
        "```python\n",
        "def extract():\n",
        "  text = \"{abstract}\"\n",
        "  w2r = {{\"waste\": [], \"transformed_resource\": []}}\n",
        "  # now read the text, assign wastes and resources lists to w2r keys\n",
        "  # directly output the newly added code\n",
        "```\"\"\".format(abstract=abstract)\n",
        "  return coded_abstract\n",
        "\n",
        "def make_formatted_prompt(abstract)-> str:\n",
        "  instruction = make_instruction_from_abstract()\n",
        "  input_x = make_coded_abstract(abstract)\n",
        "\n",
        "  llama31_prompt=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "\n",
        "{}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
        "\n",
        "  formatted_prompt = llama31_prompt.format(instruction, input_x)\n",
        "  return formatted_prompt\n"
      ],
      "metadata": {
        "id": "4PftrCeyXDUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test one example**"
      ],
      "metadata": {
        "id": "qISpdzam0LZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextIteratorStreamer\n",
        "\n",
        "abstract = \"The valorization of tannins from forest by-products is a major opportunity for the sustainable development of the forestry industry. Herein we report the laccase-mediated polymerization of tannins obtained from an aqueous pine bark extract. The reaction was conducted under an oxygen atmosphere at 50°C for 60 min and followed by UV–Vis, fluorescence intensity, phenol content, and viscosity measurements. An insoluble polymer was obtained after 45 min, which was attributed to coupling reactions triggered by phenoxyl radicals within the tannins mixture. The polymer showed a marked increase in thermal stability compared with the precursor pine bark extract, with a total mass loss of less than 12% at temperatures up to 500°C, suggesting potential practical applications in flame retardant materials. Additionally, the polymer showed an 85% DPPH activity and a 60% attenuation of singlet oxygen release upon light irradiation, which supports antioxidant and photoprotective properties for the prepared material. To the best of our knowledge, this is the first report to describe the formation of an insoluble polymer by direct enzymatic reaction of an aqueous tannin extract. In this case, soluble tannins are the sole reactants used to produce a promising versatile material for forest waste valorization. © 2024 Wiley Periodicals LLC.\"\n",
        "inputs_string = make_formatted_prompt(abstract)\n",
        "\n",
        "inputs = tokenizer([inputs_string], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Initialize the TextIteratorStreamer\n",
        "text_iter_streamer = TextIteratorStreamer(tokenizer)\n",
        "\n",
        "# Generate the content using the model and the streamer\n",
        "_ = model.generate(**inputs, streamer=text_iter_streamer, max_new_tokens=256)\n",
        "\n",
        "# Collect the generated tokens from the streamer and join them into a single string\n",
        "generated_text = \"\".join([token for token in text_iter_streamer])\n",
        "\n",
        "# Remove the original input part from the generated text, if needed\n",
        "original_input_text = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)\n",
        "generated_text = generated_text[len(original_input_text):].strip()\n",
        "\n",
        "# Print or use the generated content\n",
        "print(\"Result: \")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-kl7356Y1nb",
        "outputId": "c3cb9efe-af7e-437f-9c85-0f8069e22435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: \n",
            "w read the text, assign wastes and resources lists to w2r keys\n",
            "  # directly output the newly added code\n",
            "```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "```python\n",
            "w2r[\"waste\"] = [\"forest by-products\"]\n",
            "w2r[\"transformed_resource\"] = [\"polymer\"]\n",
            "```\n",
            "<|eot_id|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference on 50 abstracts**"
      ],
      "metadata": {
        "id": "em0b1KGl0OpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "import json\n",
        "import time\n",
        "import ast\n",
        "import re"
      ],
      "metadata": {
        "id": "cwyWpEWv0_ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define some functions"
      ],
      "metadata": {
        "id": "zXfRjg9s5mCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract(abstract, args):\n",
        "  inputs_string = make_formatted_prompt(abstract)\n",
        "  inputs = tokenizer([inputs_string], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "  # Initialize the TextIteratorStreamer\n",
        "  text_iter_streamer = TextIteratorStreamer(tokenizer)\n",
        "\n",
        "  # generate\n",
        "  _ = model.generate(**inputs, streamer=text_iter_streamer, max_new_tokens=512)\n",
        "  generated_text = \"\".join([token for token in text_iter_streamer])\n",
        "\n",
        "  # Remove the original input part from the generated text, if needed\n",
        "  original_input_text = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)\n",
        "  generated_text = generated_text[len(original_input_text):].strip()\n",
        "\n",
        "  return generated_text\n",
        "\n",
        "def extract_postprocessing(result):\n",
        "  w2r = {\"waste\": [], \"transforming_process\": [], \"transformed_resource\": []}\n",
        "  try:\n",
        "    # Regular expression pattern to match w2r assignments\n",
        "    pattern = r'w2r\\[\"(?P<key>\\w+)\"\\]\\s*=\\s*(?P<value>\\[.*?\\])'\n",
        "    # Find all matches in the code string\n",
        "    matches = re.finditer(pattern, result, re.DOTALL)\n",
        "    for match in matches:\n",
        "      key = match.group('key')\n",
        "      value_str = match.group('value')\n",
        "      try:\n",
        "        # Safely evaluate the list using ast.literal_eval\n",
        "        value = ast.literal_eval(value_str)\n",
        "        if isinstance(value, list):\n",
        "          w2r[key] = value\n",
        "        else:\n",
        "          print(f\"Warning: The value for '{key}' is not a list.\")\n",
        "      except Exception as e:\n",
        "        print(f\"Error evaluating the list for '{key}': {e}\")\n",
        "  except Exception as e:\n",
        "    print(\"An error occurred while parsing the code string:\", e)\n",
        "  return w2r\n",
        "\n",
        "def check_make_dir(directory, exist_ok=False):\n",
        "  if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "    return directory\n",
        "  else:\n",
        "    if not exist_ok:\n",
        "      i = 1\n",
        "      # increment until finding an available name\n",
        "      new_dir = f\"{directory}_{i}\"\n",
        "      while os.path.exists(new_dir):\n",
        "        i += 1\n",
        "        new_dir = f\"{directory}_{i}\"\n",
        "      os.makedirs(new_dir)\n",
        "      return new_dir\n",
        "    return directory"
      ],
      "metadata": {
        "id": "kqKhIyNZ1QN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_abstracts(args):\n",
        "\n",
        "  # num, model, prompt, save_dir, shot_length, shot_k\n",
        "\n",
        "  result_json_file = os.path.join(args.save_dir, \"w2r_results.json\")\n",
        "  result_invalid_file = os.path.join(args.save_dir, \"w2r_invalid.txt\")\n",
        "  result_invalid_doi_file = os.path.join(args.save_dir, \"w2r_invalid_doi.txt\")\n",
        "\n",
        "  df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/W2R/scopus_waste2resource.csv\")\n",
        "  abstract_list = df[\"Abstract\"].tolist()\n",
        "  doi_list = df[\"DOI\"].tolist()\n",
        "\n",
        "  if args.start_index:\n",
        "    abstract_list = abstract_list[args.start_index:]\n",
        "    doi_list = doi_list[args.start_index:]\n",
        "\n",
        "  if args.num > 0:\n",
        "    abstract_list = abstract_list[:args.num]\n",
        "    doi_list = doi_list[:args.num]\n",
        "\n",
        "  result_json_list = []\n",
        "  result_invalid_str = \"\"\n",
        "  result_invalid_doi_list = []\n",
        "\n",
        "  total_time = 0\n",
        "\n",
        "  for i, abstract in enumerate(abstract_list):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # get llm output and process\n",
        "    coded_abstract = abstract   # no need to wrap\n",
        "    result_str = extract(coded_abstract, args)\n",
        "    result_json = extract_postprocessing(result_str)\n",
        "\n",
        "    # add the referece and append\n",
        "    result_json[\"reference\"] = doi_list[i]\n",
        "    result_json_list.append(result_json)\n",
        "\n",
        "    # check if the extracted information is valid\n",
        "    if len(result_json[\"waste\"]) == 0 and len(result_json[\"transforming_process\"]) == 0 and len(result_json[\"transformed_resource\"]) == 0:\n",
        "      result_invalid_str += result_str + \"\\n\\n----------\\n\\n\"\n",
        "      result_invalid_doi_list.append(doi_list[i])\n",
        "\n",
        "    logging.info(\"----------------------------------\")\n",
        "    logging.info(\"Processing abstract {}\".format(i))\n",
        "    logging.info(\"Coded abstract: \\n{}\".format(coded_abstract))\n",
        "    logging.info(\"LLM response: \\n{}\".format(result_str))\n",
        "    logging.info(\"Extracted w2r: \\n{}\".format(result_json))\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time += end_time - start_time\n",
        "    logging.info(\"Time taken: {:.2f} seconds\".format(end_time - start_time))\n",
        "    print(\"Processing abstract {}, time taken: {:.2f} seconds\".format(i, end_time - start_time))\n",
        "    # end for loop\n",
        "\n",
        "    # save results each 10 abstracts\n",
        "    if i % 10 == 0:\n",
        "      with open(result_json_file, 'w') as file:\n",
        "        json.dump(result_json_list, file, indent=4)\n",
        "\n",
        "  # save the final result\n",
        "  with open(result_json_file, 'w') as file:\n",
        "    json.dump(result_json_list, file, indent=4)\n",
        "\n",
        "  try:\n",
        "    with open(result_invalid_file, 'w') as file:\n",
        "      file.write(result_invalid_str)\n",
        "  except:\n",
        "    with open(result_invalid_file, 'w', encoding='utf-8') as file:\n",
        "      file.write(result_invalid_str)\n",
        "\n",
        "  with open(result_invalid_doi_file, 'w') as file:\n",
        "    for invalid_doi in result_invalid_doi_list:   # if empty, doi = nan, then need to convert to string\n",
        "      file.write(str(invalid_doi) + '\\n')\n",
        "\n",
        "  logging.info(\"-------------\"*5)\n",
        "  logging.info(\"Successfully extracted: {} / {}\".format(len(result_json_list), len(abstract_list)))\n",
        "  logging.info(\"Total time: {}, averaged time: {} seconds\".format(total_time, total_time/len(result_json_list)))\n",
        "\n"
      ],
      "metadata": {
        "id": "xjdS-Zne0SHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "run inference"
      ],
      "metadata": {
        "id": "HQrAQdY95rii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "  def __init__(self):\n",
        "    self.num = 50\n",
        "    self.start_index = None\n",
        "    self.save_dir = \"/content/drive/MyDrive/Colab Notebooks/W2R/extraction_finetune_unsloth/result_codestyle3\"\n",
        "    self.save_dir_rewrite = True\n",
        "    self.repeat = 5\n",
        "\n",
        "# Create an instance of Args\n",
        "args = Args()\n",
        "base_folder = args.save_dir\n",
        "\n",
        "# Run the process_abstracts function\n",
        "for i in range(args.repeat):\n",
        "  print(\"Running experiment {}/{}\".format(i+1, args.repeat))\n",
        "  logging.info(\"Running experiment {}/{}\".format(i+1, args.repeat))\n",
        "\n",
        "\n",
        "  # create subfolder in the save_dir: run_{i}\n",
        "  save_dir = os.path.join(base_folder, \"run_{}\".format(i))\n",
        "  args.save_dir = check_make_dir(save_dir, exist_ok=args.save_dir_rewrite)\n",
        "\n",
        "  # set logging file\n",
        "  logger = logging.getLogger()\n",
        "  if logger.hasHandlers():\n",
        "    logger.handlers.clear()\n",
        "  log_file = os.path.join(args.save_dir, \"extraction_log.log\")\n",
        "  logging.basicConfig(filename=log_file, filemode='w', level=logging.INFO, format='%(message)s')\n",
        "\n",
        "  # Log each argument and its value\n",
        "  for arg, value in vars(args).items():\n",
        "    logging.info(f'Argument {arg}: {value}')\n",
        "    print(f'{arg}: {value}')\n",
        "  logging.info(\"-------------\"*5)\n",
        "\n",
        "  process_abstracts(args)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJLbmk1H3WSD",
        "outputId": "88b0a457-95f9-457a-c67d-c4b5d3a030e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running experiment 1/5\n",
            "num: 50\n",
            "start_index: None\n",
            "save_dir: /content/drive/MyDrive/Colab Notebooks/W2R/extraction_finetune_unsloth/result_codestyle3/run_0\n",
            "save_dir_rewrite: True\n",
            "repeat: 5\n",
            "Processing abstract 0, time taken: 2.61 seconds\n",
            "Processing abstract 1, time taken: 6.24 seconds\n",
            "Processing abstract 2, time taken: 3.53 seconds\n",
            "Processing abstract 3, time taken: 4.18 seconds\n",
            "Processing abstract 4, time taken: 2.83 seconds\n",
            "Processing abstract 5, time taken: 4.00 seconds\n",
            "Processing abstract 6, time taken: 2.54 seconds\n",
            "Processing abstract 7, time taken: 3.23 seconds\n",
            "Processing abstract 8, time taken: 3.43 seconds\n",
            "Processing abstract 9, time taken: 7.10 seconds\n",
            "Processing abstract 10, time taken: 2.82 seconds\n",
            "Processing abstract 11, time taken: 5.46 seconds\n",
            "Processing abstract 12, time taken: 3.54 seconds\n",
            "Processing abstract 13, time taken: 2.90 seconds\n",
            "Processing abstract 14, time taken: 2.56 seconds\n",
            "Processing abstract 15, time taken: 8.50 seconds\n",
            "Processing abstract 16, time taken: 3.15 seconds\n",
            "Processing abstract 17, time taken: 2.36 seconds\n",
            "Processing abstract 18, time taken: 2.87 seconds\n",
            "Processing abstract 19, time taken: 3.68 seconds\n",
            "Processing abstract 20, time taken: 3.61 seconds\n",
            "Processing abstract 21, time taken: 2.70 seconds\n",
            "Processing abstract 22, time taken: 2.98 seconds\n",
            "Processing abstract 23, time taken: 4.34 seconds\n",
            "Processing abstract 24, time taken: 3.77 seconds\n",
            "Processing abstract 25, time taken: 3.48 seconds\n",
            "Processing abstract 26, time taken: 4.66 seconds\n",
            "Processing abstract 27, time taken: 3.86 seconds\n",
            "Processing abstract 28, time taken: 2.70 seconds\n",
            "Processing abstract 29, time taken: 2.97 seconds\n",
            "Processing abstract 30, time taken: 3.02 seconds\n",
            "Processing abstract 31, time taken: 4.19 seconds\n",
            "Processing abstract 32, time taken: 3.53 seconds\n",
            "Processing abstract 33, time taken: 2.85 seconds\n",
            "Processing abstract 34, time taken: 2.98 seconds\n",
            "Processing abstract 35, time taken: 2.87 seconds\n",
            "Processing abstract 36, time taken: 4.07 seconds\n",
            "Processing abstract 37, time taken: 2.91 seconds\n",
            "Processing abstract 38, time taken: 2.84 seconds\n",
            "Processing abstract 39, time taken: 3.05 seconds\n",
            "Processing abstract 40, time taken: 3.85 seconds\n",
            "Processing abstract 41, time taken: 3.11 seconds\n",
            "Processing abstract 42, time taken: 2.43 seconds\n",
            "Processing abstract 43, time taken: 2.84 seconds\n",
            "Processing abstract 44, time taken: 2.69 seconds\n",
            "Processing abstract 45, time taken: 4.93 seconds\n",
            "Processing abstract 46, time taken: 3.72 seconds\n",
            "Processing abstract 47, time taken: 2.99 seconds\n",
            "Processing abstract 48, time taken: 3.73 seconds\n",
            "Processing abstract 49, time taken: 3.36 seconds\n",
            "Running experiment 2/5\n",
            "num: 50\n",
            "start_index: None\n",
            "save_dir: /content/drive/MyDrive/Colab Notebooks/W2R/extraction_finetune_unsloth/result_codestyle3/run_1\n",
            "save_dir_rewrite: True\n",
            "repeat: 5\n",
            "Processing abstract 0, time taken: 3.00 seconds\n",
            "Processing abstract 1, time taken: 4.70 seconds\n",
            "Processing abstract 2, time taken: 4.74 seconds\n",
            "Processing abstract 3, time taken: 3.57 seconds\n",
            "Processing abstract 4, time taken: 2.61 seconds\n",
            "Processing abstract 5, time taken: 3.51 seconds\n",
            "Processing abstract 6, time taken: 3.30 seconds\n",
            "Processing abstract 7, time taken: 3.27 seconds\n",
            "Processing abstract 8, time taken: 3.30 seconds\n",
            "Processing abstract 9, time taken: 4.06 seconds\n",
            "Processing abstract 10, time taken: 3.69 seconds\n",
            "Processing abstract 11, time taken: 5.64 seconds\n",
            "Processing abstract 12, time taken: 2.74 seconds\n",
            "Processing abstract 13, time taken: 2.51 seconds\n",
            "Processing abstract 14, time taken: 3.36 seconds\n",
            "Processing abstract 15, time taken: 7.40 seconds\n",
            "Processing abstract 16, time taken: 3.46 seconds\n",
            "Processing abstract 17, time taken: 3.06 seconds\n",
            "Processing abstract 18, time taken: 3.52 seconds\n",
            "Processing abstract 19, time taken: 2.79 seconds\n",
            "Processing abstract 20, time taken: 3.17 seconds\n",
            "Processing abstract 21, time taken: 3.10 seconds\n",
            "Processing abstract 22, time taken: 3.34 seconds\n",
            "Processing abstract 23, time taken: 3.88 seconds\n",
            "Processing abstract 24, time taken: 2.80 seconds\n",
            "Processing abstract 25, time taken: 3.90 seconds\n",
            "Processing abstract 26, time taken: 5.70 seconds\n",
            "Processing abstract 27, time taken: 2.83 seconds\n",
            "Processing abstract 28, time taken: 2.60 seconds\n",
            "Processing abstract 29, time taken: 5.04 seconds\n",
            "Processing abstract 30, time taken: 3.37 seconds\n",
            "Processing abstract 31, time taken: 4.11 seconds\n",
            "Processing abstract 32, time taken: 3.86 seconds\n",
            "Processing abstract 33, time taken: 4.11 seconds\n",
            "Processing abstract 34, time taken: 2.95 seconds\n",
            "Processing abstract 35, time taken: 2.64 seconds\n",
            "Processing abstract 36, time taken: 3.17 seconds\n",
            "Processing abstract 37, time taken: 3.84 seconds\n",
            "Processing abstract 38, time taken: 3.23 seconds\n",
            "Processing abstract 39, time taken: 2.87 seconds\n",
            "Processing abstract 40, time taken: 3.22 seconds\n",
            "Processing abstract 41, time taken: 4.59 seconds\n",
            "Processing abstract 42, time taken: 2.83 seconds\n",
            "Processing abstract 43, time taken: 2.91 seconds\n",
            "Processing abstract 44, time taken: 2.58 seconds\n",
            "Processing abstract 45, time taken: 4.75 seconds\n",
            "Processing abstract 46, time taken: 3.95 seconds\n",
            "Processing abstract 47, time taken: 2.93 seconds\n",
            "Processing abstract 48, time taken: 3.23 seconds\n",
            "Processing abstract 49, time taken: 3.43 seconds\n",
            "Running experiment 3/5\n",
            "num: 50\n",
            "start_index: None\n",
            "save_dir: /content/drive/MyDrive/Colab Notebooks/W2R/extraction_finetune_unsloth/result_codestyle3/run_2\n",
            "save_dir_rewrite: True\n",
            "repeat: 5\n",
            "Processing abstract 0, time taken: 3.05 seconds\n",
            "Processing abstract 1, time taken: 4.83 seconds\n",
            "Processing abstract 2, time taken: 2.80 seconds\n",
            "Processing abstract 3, time taken: 4.72 seconds\n",
            "Processing abstract 4, time taken: 2.95 seconds\n",
            "Processing abstract 5, time taken: 2.88 seconds\n",
            "Processing abstract 6, time taken: 2.56 seconds\n",
            "Processing abstract 7, time taken: 3.39 seconds\n",
            "Processing abstract 8, time taken: 3.91 seconds\n",
            "Processing abstract 9, time taken: 4.61 seconds\n",
            "Processing abstract 10, time taken: 2.81 seconds\n",
            "Processing abstract 11, time taken: 6.43 seconds\n",
            "Processing abstract 12, time taken: 3.07 seconds\n",
            "Processing abstract 13, time taken: 2.53 seconds\n",
            "Processing abstract 14, time taken: 2.61 seconds\n",
            "Processing abstract 15, time taken: 8.57 seconds\n",
            "Processing abstract 16, time taken: 3.41 seconds\n",
            "Processing abstract 17, time taken: 2.71 seconds\n",
            "Processing abstract 18, time taken: 4.14 seconds\n",
            "Processing abstract 19, time taken: 3.10 seconds\n",
            "Processing abstract 20, time taken: 3.08 seconds\n",
            "Processing abstract 21, time taken: 2.74 seconds\n",
            "Processing abstract 22, time taken: 4.77 seconds\n",
            "Processing abstract 23, time taken: 3.68 seconds\n",
            "Processing abstract 24, time taken: 3.03 seconds\n",
            "Processing abstract 25, time taken: 3.71 seconds\n",
            "Processing abstract 26, time taken: 4.74 seconds\n",
            "Processing abstract 27, time taken: 2.83 seconds\n",
            "Processing abstract 28, time taken: 2.98 seconds\n",
            "Processing abstract 29, time taken: 4.52 seconds\n",
            "Processing abstract 30, time taken: 4.20 seconds\n",
            "Processing abstract 31, time taken: 3.33 seconds\n",
            "Processing abstract 32, time taken: 2.98 seconds\n",
            "Processing abstract 33, time taken: 3.26 seconds\n",
            "Processing abstract 34, time taken: 3.84 seconds\n",
            "Processing abstract 35, time taken: 2.59 seconds\n",
            "Processing abstract 36, time taken: 2.88 seconds\n",
            "Processing abstract 37, time taken: 2.90 seconds\n",
            "Processing abstract 38, time taken: 3.70 seconds\n",
            "Processing abstract 39, time taken: 2.72 seconds\n",
            "Processing abstract 40, time taken: 3.16 seconds\n",
            "Processing abstract 41, time taken: 3.17 seconds\n",
            "Processing abstract 42, time taken: 3.26 seconds\n",
            "Processing abstract 43, time taken: 4.05 seconds\n",
            "Processing abstract 44, time taken: 2.53 seconds\n",
            "Processing abstract 45, time taken: 4.75 seconds\n",
            "Processing abstract 46, time taken: 4.57 seconds\n",
            "Processing abstract 47, time taken: 3.14 seconds\n",
            "Processing abstract 48, time taken: 3.84 seconds\n",
            "Processing abstract 49, time taken: 2.78 seconds\n",
            "Running experiment 4/5\n",
            "num: 50\n",
            "start_index: None\n",
            "save_dir: /content/drive/MyDrive/Colab Notebooks/W2R/extraction_finetune_unsloth/result_codestyle3/run_3\n",
            "save_dir_rewrite: True\n",
            "repeat: 5\n",
            "Processing abstract 0, time taken: 3.30 seconds\n",
            "Processing abstract 1, time taken: 5.27 seconds\n",
            "Processing abstract 2, time taken: 3.47 seconds\n",
            "Processing abstract 3, time taken: 3.70 seconds\n",
            "Processing abstract 4, time taken: 4.23 seconds\n",
            "Processing abstract 5, time taken: 3.47 seconds\n",
            "Processing abstract 6, time taken: 2.59 seconds\n",
            "Processing abstract 7, time taken: 2.97 seconds\n",
            "Processing abstract 8, time taken: 4.39 seconds\n",
            "Processing abstract 9, time taken: 4.34 seconds\n",
            "Processing abstract 10, time taken: 3.03 seconds\n",
            "Processing abstract 11, time taken: 6.43 seconds\n",
            "Processing abstract 12, time taken: 2.88 seconds\n",
            "Processing abstract 13, time taken: 2.56 seconds\n",
            "Processing abstract 14, time taken: 2.57 seconds\n",
            "Processing abstract 15, time taken: 8.47 seconds\n",
            "Processing abstract 16, time taken: 3.47 seconds\n",
            "Processing abstract 17, time taken: 2.40 seconds\n",
            "Processing abstract 18, time taken: 3.81 seconds\n",
            "Processing abstract 19, time taken: 3.76 seconds\n",
            "Processing abstract 20, time taken: 3.30 seconds\n",
            "Processing abstract 21, time taken: 2.69 seconds\n",
            "Processing abstract 22, time taken: 3.97 seconds\n",
            "Processing abstract 23, time taken: 4.47 seconds\n",
            "Processing abstract 24, time taken: 3.29 seconds\n",
            "Processing abstract 25, time taken: 4.32 seconds\n",
            "Processing abstract 26, time taken: 6.03 seconds\n",
            "Processing abstract 27, time taken: 2.49 seconds\n",
            "Processing abstract 28, time taken: 2.76 seconds\n",
            "Processing abstract 29, time taken: 2.64 seconds\n",
            "Processing abstract 30, time taken: 3.61 seconds\n",
            "Processing abstract 31, time taken: 5.20 seconds\n",
            "Processing abstract 32, time taken: 3.31 seconds\n",
            "Processing abstract 33, time taken: 3.05 seconds\n",
            "Processing abstract 34, time taken: 3.35 seconds\n",
            "Processing abstract 35, time taken: 3.34 seconds\n",
            "Processing abstract 36, time taken: 3.16 seconds\n",
            "Processing abstract 37, time taken: 3.03 seconds\n",
            "Processing abstract 38, time taken: 3.31 seconds\n",
            "Processing abstract 39, time taken: 3.88 seconds\n",
            "Processing abstract 40, time taken: 3.13 seconds\n",
            "Processing abstract 41, time taken: 3.50 seconds\n",
            "Processing abstract 42, time taken: 2.80 seconds\n",
            "Processing abstract 43, time taken: 3.93 seconds\n",
            "Processing abstract 44, time taken: 3.15 seconds\n",
            "Processing abstract 45, time taken: 5.42 seconds\n",
            "Processing abstract 46, time taken: 4.15 seconds\n",
            "Processing abstract 47, time taken: 3.71 seconds\n",
            "Processing abstract 48, time taken: 3.36 seconds\n",
            "Processing abstract 49, time taken: 2.68 seconds\n",
            "Running experiment 5/5\n",
            "num: 50\n",
            "start_index: None\n",
            "save_dir: /content/drive/MyDrive/Colab Notebooks/W2R/extraction_finetune_unsloth/result_codestyle3/run_4\n",
            "save_dir_rewrite: True\n",
            "repeat: 5\n",
            "Processing abstract 0, time taken: 2.73 seconds\n",
            "Processing abstract 1, time taken: 6.15 seconds\n",
            "Processing abstract 2, time taken: 3.49 seconds\n",
            "Processing abstract 3, time taken: 3.80 seconds\n",
            "Processing abstract 4, time taken: 3.06 seconds\n",
            "Processing abstract 5, time taken: 3.27 seconds\n",
            "Processing abstract 6, time taken: 2.57 seconds\n",
            "Processing abstract 7, time taken: 3.00 seconds\n",
            "Processing abstract 8, time taken: 3.41 seconds\n",
            "Processing abstract 9, time taken: 5.87 seconds\n",
            "Processing abstract 10, time taken: 2.86 seconds\n",
            "Processing abstract 11, time taken: 5.23 seconds\n",
            "Processing abstract 12, time taken: 3.29 seconds\n",
            "Processing abstract 13, time taken: 3.49 seconds\n",
            "Processing abstract 14, time taken: 2.56 seconds\n",
            "Processing abstract 15, time taken: 7.00 seconds\n",
            "Processing abstract 16, time taken: 3.91 seconds\n",
            "Processing abstract 17, time taken: 2.31 seconds\n",
            "Processing abstract 18, time taken: 3.24 seconds\n",
            "Processing abstract 19, time taken: 3.20 seconds\n",
            "Processing abstract 20, time taken: 4.33 seconds\n",
            "Processing abstract 21, time taken: 2.73 seconds\n",
            "Processing abstract 22, time taken: 3.11 seconds\n",
            "Processing abstract 23, time taken: 3.77 seconds\n",
            "Processing abstract 24, time taken: 4.00 seconds\n",
            "Processing abstract 25, time taken: 3.91 seconds\n",
            "Processing abstract 26, time taken: 4.91 seconds\n",
            "Processing abstract 27, time taken: 3.32 seconds\n",
            "Processing abstract 28, time taken: 3.42 seconds\n",
            "Processing abstract 29, time taken: 2.98 seconds\n",
            "Processing abstract 30, time taken: 3.17 seconds\n",
            "Processing abstract 31, time taken: 3.34 seconds\n",
            "Processing abstract 32, time taken: 3.93 seconds\n",
            "Processing abstract 33, time taken: 3.37 seconds\n",
            "Processing abstract 34, time taken: 2.96 seconds\n",
            "Processing abstract 35, time taken: 2.76 seconds\n",
            "Processing abstract 36, time taken: 4.51 seconds\n",
            "Processing abstract 37, time taken: 3.25 seconds\n",
            "Processing abstract 38, time taken: 2.87 seconds\n",
            "Processing abstract 39, time taken: 3.06 seconds\n",
            "Processing abstract 40, time taken: 3.35 seconds\n",
            "Processing abstract 41, time taken: 3.72 seconds\n",
            "Processing abstract 42, time taken: 2.57 seconds\n",
            "Processing abstract 43, time taken: 3.22 seconds\n",
            "Processing abstract 44, time taken: 2.59 seconds\n",
            "Processing abstract 45, time taken: 6.24 seconds\n",
            "Processing abstract 46, time taken: 3.71 seconds\n",
            "Processing abstract 47, time taken: 2.64 seconds\n",
            "Processing abstract 48, time taken: 3.86 seconds\n",
            "Processing abstract 49, time taken: 3.28 seconds\n"
          ]
        }
      ]
    }
  ]
}