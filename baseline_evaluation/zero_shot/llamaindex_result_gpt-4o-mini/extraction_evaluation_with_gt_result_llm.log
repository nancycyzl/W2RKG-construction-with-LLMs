Parameters:
method=llm
model=llama3.1
thre=0.8
gt_file=extraction_groundtruth.json
pr_file=baseline_evaluation1\llamaindex_result_gpt-4o-mini\llamaindex_result_gpt-4o-mini.json
pr_folder=None
save_dir=baseline_evaluation1\llamaindex_result_gpt-4o-mini_1
metrics_update_file=
comment=
Evaluating file: baseline_evaluation1\llamaindex_result_gpt-4o-mini\llamaindex_result_gpt-4o-mini.json
Evaluating 0 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['forest by-product', 'aqueous pine bark extract']
Resolving: pine bark extract
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolving: tannins from forest by-product
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['aqueous pine bark extract', 'forest by-product']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['insoluble polymer', 'flame retardant material']
Resolving: insoluble polymer
directly matched: insoluble polymer
Resolved prediction: ['insoluble polymer']
------------------------------------------------------------
Evaluating 1 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['date pit', 'peanut shell', 'coffee ground', 'tea waste']
Resolving: date pits and peanut shell
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: list: ["a: date pits", "b: bio-wastes", "c: agro-wastes"]. sample: date pits and peanut shell.
answer: yes. a.
Resolving: coffee grounds and tea waste
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. c.
Resolving: date pit
directly matched: date pit
Resolving: coffee ground
directly matched: coffee ground
Resolving: peanut shell
directly matched: peanut shell
Resolving: date pits and tea waste
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: list: ['a: date pit', 'b: peanut shell', 'c: coffee ground', 'd: tea waste']. 
sample: date pits and tea waste. 

answer: yes. a&d.
Resolving: tea waste
directly matched: tea waste
Resolving: tea waste and peanut shell
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: list: ['a: date pit', 'b: peanut shell', 'c: coffee ground', 'd: tea waste']. sample: tea waste and peanut shell.
answer: yes. b and d.
Resolving: coffee grounds and peanut shell
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. c&d.
Resolved prediction: ['date pit', 'coffee ground', 'date pit', 'coffee ground', 'peanut shell', 'date pits and tea waste', 'tea waste', 'tea waste', 'coffee grounds and peanut shell']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['char', 'hydrogen-rich gas', 'biochars', 'solid fuel', 'biofertilizers', 'carbon material']
Resolving: hydrogen-rich gas
directly matched: hydrogen-rich gas
Resolving: char
directly matched: char
Resolved prediction: ['hydrogen-rich gas', 'char']
------------------------------------------------------------
Evaluating 2 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['textile residue', 'end-of-life fire-protecting t-shirt', 'protective clothing with meta-aramid fiber']
Resolving: shredded fibers from protective clothing
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. c.
Resolving: end-of-life fire-protecting t-shirt
directly matched: end-of-life fire-protecting t-shirt
Resolving: textile residue
directly matched: textile residue
Resolved prediction: ['protective clothing with meta-aramid fiber', 'end-of-life fire-protecting t-shirt', 'textile residue']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['reinforcement materials in cement-based matrix', 'recycled fiber', 'laminated fabric-reinforced cementitious matrix']
Resolving: aged fiber
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolving: nonwoven fabric layer
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: list: ['a: reinforcement materials in cement-based matrix', 'b: recycled fiber', 'c: laminated fabric-reinforced cementitious matrix']. 
sample: laminated fabric.

answer: yes. c.
Resolving: recycled fiber
directly matched: recycled fiber
Resolved prediction: ['recycled fiber', 'laminated fabric-reinforced cementitious matrix', 'recycled fiber']
------------------------------------------------------------
Evaluating 3 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['waste vulcanized rubber', 'waste vulcanized natural rubber', 'waste vulcanized emulsion type butadiene-based rubber', 'waste vulcanized nitrile-butadiene rubber glove', 'waste vulcanized emulsion type diene-based rubber']
Resolving: waste vulcanized natural rubber
directly matched: waste vulcanized natural rubber
Resolving: waste vulcanized rubber
directly matched: waste vulcanized rubber
Resolving: waste vulcanized emulsion type butadiene-based rubber
directly matched: waste vulcanized emulsion type butadiene-based rubber
Resolved prediction: ['waste vulcanized natural rubber', 'waste vulcanized rubber', 'waste vulcanized emulsion type butadiene-based rubber']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: []
Resolving: recycled resource
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: list: [recycled resource]. sample: recyclable materials.

answer: yes. 0.
Resolving: nitrile-butadiene rubber (nbr) glove
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolved prediction: ['recycled resource', 'nitrile-butadiene rubber (nbr) glove']
------------------------------------------------------------
Evaluating 4 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['plastic waste', 'municipal solid waste']
Resolving: plastic waste
directly matched: plastic waste
Resolved prediction: ['plastic waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['hydrogen', 'chemical', 'syngas']
Resolving: chemical
directly matched: chemical
Resolving: hydrogen
directly matched: hydrogen
Resolved prediction: ['chemical', 'hydrogen']
------------------------------------------------------------
Evaluating 5 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['lignocellulosic waste', 'pine sawdust', 'wheat straw']
Resolving: lignocellulosic waste
directly matched: lignocellulosic waste
Resolving: wheat straw
directly matched: wheat straw
Resolving: pine sawdust (psd)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolving: pretreated wheat straw
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. c.
Resolved prediction: ['lignocellulosic waste', 'wheat straw', 'pine sawdust', 'wheat straw']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['hydrolytic enzyme', 'cellulases', 'xylanases', '\u03b2-glucosidases']
Resolving: hydrolytic enzyme
directly matched: hydrolytic enzyme
Resolving: reducing sugar
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['hydrolytic enzyme', 'reducing sugar']
------------------------------------------------------------
Evaluating 6 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['plastic waste']
Resolving: hdpe
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: plastic waste
directly matched: plastic waste
Resolved prediction: ['plastic waste', 'plastic waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['h2']
Resolving: h2
directly matched: h2
Resolved prediction: ['h2']
------------------------------------------------------------
Evaluating 7 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['biomass waste']
Resolving: biomass waste
directly matched: biomass waste
Resolved prediction: ['biomass waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['ethanol', 'acetaldehyde', 'hydrogen']
Resolving: acetaldehyde
directly matched: acetaldehyde
Resolving: ethanol
directly matched: ethanol
Resolved prediction: ['acetaldehyde', 'ethanol']
------------------------------------------------------------
Evaluating 8 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['digestate from anaerobic digestion of food waste']
Resolving: food waste
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['digestate from anaerobic digestion of food waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biochar', 'syngas', 'bio-oil']
Resolving: biochar
directly matched: biochar
Resolved prediction: ['biochar']
------------------------------------------------------------
Evaluating 9 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['agricultural waste metricals, residues and by-product', 'crop residue', 'straw', 'husk', 'shell', 'animal manure', 'food processing waste', 'forestry residue', 'microalgae']
Resolving: animal manure
directly matched: animal manure
Resolving: agricultural waste material
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: forestry residue
directly matched: forestry residue
Resolving: crop residue
directly matched: crop residue
Resolving: food processing waste
directly matched: food processing waste
Resolving: agricultural waste valorization (biochar)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['animal manure', 'agricultural waste metricals, residues and by-product', 'forestry residue', 'crop residue', 'food processing waste', 'agricultural waste valorization (biochar)']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biofuel', 'biochar for soil amendment']
Resolving: biofuels
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: soil amendment
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolved prediction: ['biofuel', 'biochar for soil amendment']
------------------------------------------------------------
Evaluating 10 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['fish waste']
Resolving: fish waste
directly matched: fish waste
Resolved prediction: ['fish waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['vitamin d3 extract']
Resolving: vitamin d3
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['vitamin d3 extract']
------------------------------------------------------------
Evaluating 11 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['biowastes', 'coffee residue', 'bracts and peels of various fruit']
Resolving: bracts and peels of various fruit
directly matched: bracts and peels of various fruit
Resolving: coffee residue
directly matched: coffee residue
Resolving: harmful waste
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: biowastes
directly matched: biowastes
Resolved prediction: ['bracts and peels of various fruit', 'coffee residue', 'biowastes', 'biowastes']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['sorbent']
Resolving: natural sorbent
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['sorbent']
------------------------------------------------------------
Evaluating 12 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['sorghum waste']
Resolving: sorghum waste
directly matched: sorghum waste
Resolved prediction: ['sorghum waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['sodium silicate', 'silica source for cr(vi) adsorbent synthesis']
Resolving: mi-cl-fdu-12 adsorbent
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['mi-cl-fdu-12 adsorbent']
------------------------------------------------------------
Evaluating 13 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['chestnut shell']
Resolving: chestnut shell
directly matched: chestnut shell
Resolved prediction: ['chestnut shell']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['natural coloring agent', 'bioactive compound']
Resolving: natural coloring agent
directly matched: natural coloring agent
Resolved prediction: ['natural coloring agent']
------------------------------------------------------------
Evaluating 14 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['lignocellulosic biomass', 'bio-waste material', 'agri-food waste']
Resolving: lignocellulosic biomass
directly matched: lignocellulosic biomass
Resolving: xylose
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolving: agri-food waste
directly matched: agri-food waste
Resolved prediction: ['lignocellulosic biomass', 'bio-waste material', 'agri-food waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['bioethanol', 'xylose']
Resolving: xylose
directly matched: xylose
Resolving: bioethanol
directly matched: bioethanol
Resolved prediction: ['xylose', 'bioethanol']
------------------------------------------------------------
Evaluating 15 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['oil palm biomass', 'mill effluent']
Resolving: oil palm biomass
directly matched: oil palm biomass
Resolving: mill effluent
directly matched: mill effluent
Resolved prediction: ['oil palm biomass', 'mill effluent']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biopolymer', 'graphene', 'biocomposites', 'mxene', 'biochemicals']
Resolving: jet biofuel
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolving: mxene
directly matched: mxene
Resolving: biodiesel
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: biocomposites
directly matched: biocomposites
Resolving: bioethanol
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: graphene
directly matched: graphene
Resolving: biopolymer
directly matched: biopolymer
Resolving: biohydrogen
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['graphene', 'mxene', 'biopolymer', 'biocomposites', 'bioethanol', 'graphene', 'biopolymer', 'biohydrogen']
------------------------------------------------------------
Evaluating 16 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['expanded polystyrene waste']
Resolving: expanded polystyrene waste
directly matched: expanded polystyrene waste
Resolved prediction: ['expanded polystyrene waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['superhydrophobic surfaces for food packaging']
Resolving: superhydrophobic surface
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['superhydrophobic surfaces for food packaging']
------------------------------------------------------------
Evaluating 17 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['face mask']
Resolving: face mask
directly matched: face mask
Resolved prediction: ['face mask']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['oil', 'fuel']
Resolving: energy-dense oil
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: value-added chemical
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['oil', 'value-added chemical']
------------------------------------------------------------
Evaluating 18 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['waste products from chemical industry']
Resolving: waste material from the chemical industry
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: waste material from the warehouse
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['waste products from chemical industry', 'waste material from the warehouse']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['hollow concrete block', 'mortar', 'masonry unit']
Resolving: hollow concrete blocks (hcbs)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: masonry unit
directly matched: masonry unit
Resolved prediction: ['hollow concrete block', 'masonry unit']
------------------------------------------------------------
Evaluating 19 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['waste polyethylene', 'plastic waste']
Resolving: waste polyethylene (pe)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['waste polyethylene']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['oil']
Resolving: light fraction (<c12)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: pyrolysis oil
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: aromatics
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['oil', 'oil', 'aromatics']
------------------------------------------------------------
Evaluating 20 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['cellulose-rich residue', 'food waste']
Resolving: grape marc extract
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: cellulose-rich residue after agar extraction
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['grape marc extract', 'cellulose-rich residue']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['gelatin film', 'food packaging']
Resolving: cellulose-containing gelatin film
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: revalorized cellulose
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['gelatin film', 'revalorized cellulose']
------------------------------------------------------------
Evaluating 21 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['bisphenol a']
Resolving: bisphenol a (bpa)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: oleic acid
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['bisphenol a', 'oleic acid']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biopolyol']
Resolving: metabolite
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: 7,10-dihydroxy-8(e)-octadecenoic acid
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['metabolite', '7,10-dihydroxy-8(e)-octadecenoic acid']
------------------------------------------------------------
Evaluating 22 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['defatted apricot seed', 'oil-bearing biomass']
Resolving: defatted apricot seeds (das)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: volatile matters from da
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['defatted apricot seed', 'defatted apricot seed']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biochar']
Resolving: das biochars (dasbs)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: co
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no. a.
Resolved prediction: ['das biochars (dasbs)', 'co']
------------------------------------------------------------
Evaluating 23 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['molasses', 'corn steep liquor', 'black soldier fly larval meal']
Resolving: enzyme-hydrolyzed black soldier fly larval meal
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. c.
Resolving: acid-hydrolyzed black soldier fly larval meal
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. c.
Resolving: corn steep liquor
directly matched: corn steep liquor
Resolving: thai molasses
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['black soldier fly larval meal', 'black soldier fly larval meal', 'corn steep liquor', 'molasses']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biobutanol', 'butanol']
Resolving: insect peptone
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: biobutanol
directly matched: biobutanol
Resolved prediction: ['insect peptone', 'biobutanol']
------------------------------------------------------------
Evaluating 24 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['biomass']
Resolving: biomass and waste
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no. a.
Resolved prediction: ['biomass and waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: []
Resolving: product
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: list: [] . sample: product.
answer: no.
Resolving: energy
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['product', 'energy']
------------------------------------------------------------
Evaluating 25 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['agro-industrial waste', 'biomass']
Resolving: agro-industrial waste
directly matched: agro-industrial waste
Resolved prediction: ['agro-industrial waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['energy', 'chemical']
Resolving: energy and chemical
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a. b.
Resolving: high value-added product
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['chemical', 'high value-added product']
------------------------------------------------------------
Evaluating 26 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['biowaste', 'crop residue', 'lignocellulosic biomass']
Resolving: crop residue
directly matched: crop residue
Resolving: biowaste
directly matched: biowaste
Resolving: lignin
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. c.
Resolving: ferulic acid (fa)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolved prediction: ['crop residue', 'biowaste', 'lignocellulosic biomass', 'crop residue']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['phenolic compound', 'ferulic acid', 'vanillin', 'vanillic acid', 'hydroxycinnamic acid', 'food packaging']
Resolving: ferulic acid (fa)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolving: reactive and bioactive compound
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: phenolic compound
directly matched: phenolic compound
Resolving: vanillin, vanillic acid and hydroxycinnamic acid
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. c d e.
Resolved prediction: ['ferulic acid', 'phenolic compound', 'phenolic compound', 'hydroxycinnamic acid']
------------------------------------------------------------
Evaluating 27 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['waste polyethylene']
Resolving: polyethylene
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a
Resolved prediction: ['waste polyethylene']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biosurfactants']
Resolving: biosurfactants
directly matched: biosurfactants
Resolved prediction: ['biosurfactants']
------------------------------------------------------------
Evaluating 28 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['grape pomace']
Resolving: grape pomace
directly matched: grape pomace
Resolved prediction: ['grape pomace']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['anthocyanins']
Resolving: dried grape pomace
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: anthocyanins
directly matched: anthocyanins
Resolving: purified extract
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['anthocyanins', 'anthocyanins', 'anthocyanins']
------------------------------------------------------------
Evaluating 29 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['waste cooking oil']
Resolving: waste cooking oil
directly matched: waste cooking oil
Resolved prediction: ['waste cooking oil']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biodiesel', 'light hydrocarbon', 'syngas', 'co', 'h2', 'liquid product', 'bioenergy and heat', 'animal feed']
Resolving: light hydrocarbon
directly matched: light hydrocarbon
Resolving: chemical feedstock
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. d.
Resolving: liquid product
directly matched: liquid product
Resolving: syngas
directly matched: syngas
Resolving: bioenergy
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. g.
Resolving: animal feed
directly matched: animal feed
Resolving: biodiesel
directly matched: biodiesel
Resolved prediction: ['light hydrocarbon', 'co', 'liquid product', 'syngas', 'bioenergy and heat', 'animal feed', 'biodiesel']
------------------------------------------------------------
Evaluating 30 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['combustible high-organic solid waste']
Resolving: combustible high-organic solid waste (hsw)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['combustible high-organic solid waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['char']
Resolving: h-kaolin
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: char
directly matched: char
Resolving: oh-kaolin
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['h-kaolin', 'char', 'oh-kaolin']
------------------------------------------------------------
Evaluating 31 / 50
Evaluating 32 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['municipal solid waste incinerated fly ash']
Resolving: municipal solid waste incinerated fly ash (mswifa)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['municipal solid waste incinerated fly ash']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['substitute for m-sand in construction material', 'concrete tile']
Resolving: mswifa-based concrete roof tile
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: m-sand
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['substitute for m-sand in construction material', 'substitute for m-sand in construction material']
------------------------------------------------------------
Evaluating 33 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['fruit waste', 'vegetable waste']
Resolving: vegetable waste
directly matched: vegetable waste
Resolved prediction: ['vegetable waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['natural antioxidant', 'nutritional enhancement of oil']
Resolving: antioxidant-rich waste extract
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: natural antioxidant
directly matched: natural antioxidant
Resolved prediction: ['natural antioxidant', 'natural antioxidant']
------------------------------------------------------------
Evaluating 34 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['agricultural residue', 'coconut husk']
Resolving: coconut husk
directly matched: coconut husk
Resolved prediction: ['coconut husk']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['syngas', 'carbon monoxide']
Resolving: pyrogenic oil
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: syngas
directly matched: syngas
Resolved prediction: ['pyrogenic oil', 'syngas']
------------------------------------------------------------
Evaluating 35 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['synthetic wastewater', 'produced sludge']
Resolving: humic acid (ha)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: produced sludge
directly matched: produced sludge
Resolving: turbidity (tb)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['humic acid (ha)', 'produced sludge', 'turbidity (tb)']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['recovered humic acid-free water']
Resolving: removed ha
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: adsorption of ha from aqueous solution
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: removed tb
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['recovered humic acid-free water', 'recovered humic acid-free water', 'removed tb']
------------------------------------------------------------
Evaluating 36 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['thermal hydrolyzed sludge']
Resolving: thermal hydrolyzed sludge (ths)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['thermal hydrolyzed sludge']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['medium-chain fatty acid', 'n-caproate', 'n-caprylate']
Resolving: medium-chain fatty acids (mcfas)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['medium-chain fatty acid']
------------------------------------------------------------
Evaluating 37 / 50
Evaluating 38 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['waste activated sludge']
Resolving: waste activated sludge (was)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['waste activated sludge']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['short-chain organic acid']
Resolving: short-chain organic acids (scfas)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['short-chain organic acid']
------------------------------------------------------------
Evaluating 39 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['industrial effluent']
Resolving: industrial effluent
directly matched: industrial effluent
Resolving: pollutants in industrial effluent
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['industrial effluent', 'industrial effluent']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['recovered water']
Resolving: treated water
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: clean water
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['recovered water', 'clean water']
------------------------------------------------------------
Evaluating 40 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['urban wastewater']
Resolving: wastewater
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['urban wastewater']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['recovered water for algriculture', 'soil amender']
Resolving: algae
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: nitrogen
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: phosphorus
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: biomass
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['algae', 'nitrogen', 'phosphorus', 'biomass']
------------------------------------------------------------
Evaluating 41 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['dam sediment', 'marble waste']
Resolving: dredged sediment
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: dam sediment
directly matched: dam sediment
Resolving: marble waste
directly matched: marble waste
Resolved prediction: ['dam sediment', 'dam sediment', 'marble waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['road subgrade material']
Resolving: road subgrade construction
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: subgrade material
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['road subgrade material', 'road subgrade material']
------------------------------------------------------------
Evaluating 42 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['nitrate pollutant']
Resolving: nitrate (no3\u2012)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['nitrate pollutant']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['ammonia', 'high-purity nh4cl']
Resolving: ammonium chloride (nh4cl)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b
Resolving: ammonia (nh3)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['high-purity nh4cl', 'ammonia (nh3)']
------------------------------------------------------------
Evaluating 43 / 50
Evaluating 44 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['municipal solid waste']
Resolving: dry combustible fraction
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: municipal solid waste (msw)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: combustible fraction
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['municipal solid waste', 'municipal solid waste', 'municipal solid waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['electrical energy']
Resolving: ghg emission
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: recovered resource
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: electrical energy
directly matched: electrical energy
Resolved prediction: ['ghg emission', 'electrical energy', 'electrical energy']
------------------------------------------------------------
Evaluating 45 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['packaging', 'dross', 'incinerator bottom ash', 'salt-slag/salt-cake hazardous waste']
Resolving: salt-slag/salt-cake hazardous waste
directly matched: salt-slag/salt-cake hazardous waste
Resolved prediction: ['salt-slag/salt-cake hazardous waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['recyclable salt', 'aluminium concentrate', 'ammonium sulphate', 'non-metallic compounds (nmcs)', 'secondary cast aluminium alloy']
Resolving: aluminium concentrate
directly matched: aluminium concentrate
Resolving: recyclable salt
directly matched: recyclable salt
Resolving: non-metallic compounds (nmcs)
directly matched: non-metallic compounds (nmcs)
Resolving: ammonium sulphate
directly matched: ammonium sulphate
Resolved prediction: ['aluminium concentrate', 'recyclable salt', 'non-metallic compounds (nmcs)', 'ammonium sulphate']
------------------------------------------------------------
Evaluating 46 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['lime sludge', 'lime slaker grit']
Resolving: lime sludge (ls)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: lime slaker grits (grits)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolved prediction: ['lime sludge', 'lime slaker grit']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['magnesium oxysulfate-based fiber cement board']
Resolving: magnesium oxysulfate (mos)-based fiber cement board
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['magnesium oxysulfate-based fiber cement board']
------------------------------------------------------------
Evaluating 47 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['food waste', 'carrot pulp waste']
Resolving: carrot pulp waste (cpw)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolved prediction: ['carrot pulp waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['fuel', 'chemical', 'syngas']
Resolving: bio-oil
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: syngas
directly matched: syngas
Resolved prediction: ['fuel', 'syngas']
------------------------------------------------------------
Evaluating 48 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['waste plastic', 'lignocellulosic biomass', 'rice straw']
Resolving: waste plastic
directly matched: waste plastic
Resolving: rice straw
directly matched: rice straw
Resolving: lignocellulosic biomass
directly matched: lignocellulosic biomass
Resolving: low-density polyethylene
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['waste plastic', 'rice straw', 'lignocellulosic biomass', 'waste plastic']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biogas', 'methane', 'biofuel']
Resolving: methane
directly matched: methane
Resolving: biogas
directly matched: biogas
Resolved prediction: ['methane', 'biogas']
------------------------------------------------------------
Evaluating 49 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['incineration bottom ash']
Resolving: incineration bottom ash (iba)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['incineration bottom ash']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['natural aggregates substitutes for pavement layer']
Resolving: restricted incineration bottom ash (iba)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: treated incineration bottom ash (iba)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['restricted incineration bottom ash (iba)', 'natural aggregates substitutes for pavement layer']
------------------------------------------------------------
Total valid abstract: 47 / 50
Saved prediction result resolution to baseline_evaluation1\llamaindex_result_gpt-4o-mini_1\prediction_resolution_llm.csv
Weighted micro precision: 0.7358857142857143, recall: 0.6604102564102564, f1: 0.6961081081081081
Weighted macro precision: 0.7733333333333334, recall: 0.7013055555555556, f1: 0.7086616161616159
Averaged jaccard: 0.6387976190476191
