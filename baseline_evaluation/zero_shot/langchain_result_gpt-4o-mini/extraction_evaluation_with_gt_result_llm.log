Parameters:
method=llm
model=llama3.1
thre=0.8
gt_file=extraction_groundtruth.json
pr_file=baseline_evaluation\langchain_result.json
pr_folder=None
save_dir=baseline_evaluation_1
metrics_update_file=
comment=
Evaluating file: baseline_evaluation\langchain_result.json
Evaluating 0 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['forest by-product', 'aqueous pine bark extract']
Resolving: tannin
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolved prediction: ['aqueous pine bark extract']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['insoluble polymer', 'flame retardant material']
Resolving: insoluble_polymer
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['insoluble polymer']
------------------------------------------------------------
Evaluating 1 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['date pit', 'peanut shell', 'coffee ground', 'tea waste']
Resolving: date_pits
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: peanut_shells
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolving: coffee_grounds
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. c.
Resolving: tea_waste
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. d.
Resolved prediction: ['date pit', 'peanut shell', 'coffee ground', 'tea waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['char', 'hydrogen-rich gas', 'biochars', 'solid fuel', 'biofertilizers', 'carbon material']
Resolving: char
directly matched: char
Resolving: hydrogen_rich_gas
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolving: biochar
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. c.
Resolving: biofertilizer
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. e.
Resolving: carbon_materials
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. c, f.
Resolved prediction: ['char', 'hydrogen-rich gas', 'biochars', 'biofertilizers', 'carbon material']
------------------------------------------------------------
Evaluating 2 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['textile residue', 'end-of-life fire-protecting t-shirt', 'protective clothing with meta-aramid fiber']
Resolving: textile_residues
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: shredded_fibers
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['textile residue', 'textile residue']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['reinforcement materials in cement-based matrix', 'recycled fiber', 'laminated fabric-reinforced cementitious matrix']
Resolving: recycled_fibers
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolving: cement_based_matrices
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: list: ['a: reinforcement materials in cement-based matrix', 'b: recycled fiber', 'c: laminated fabric-reinforced cementitious matrix']. 
sample: cement_based_matrices.
answer: yes. a.
Resolved prediction: ['recycled fiber', 'reinforcement materials in cement-based matrix']
------------------------------------------------------------
Evaluating 3 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['waste vulcanized rubber', 'waste vulcanized natural rubber', 'waste vulcanized emulsion type butadiene-based rubber', 'waste vulcanized nitrile-butadiene rubber glove', 'waste vulcanized emulsion type diene-based rubber']
Resolving: waste_vulcanized_rubbers
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. c.
Resolving: waste_vulcanized_natural_rubber
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolving: waste_vulcanized_emulsion_type_butadiene_based_rubbers
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. c.
Resolving: nitrile_butadiene_rubber_glove
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. d.
Resolved prediction: ['waste vulcanized emulsion type butadiene-based rubber', 'waste vulcanized natural rubber', 'waste vulcanized emulsion type butadiene-based rubber', 'waste vulcanized nitrile-butadiene rubber glove']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: []
Resolving: resources_from_waste_vulcanized_rubbers
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b
Resolved prediction: ['resources_from_waste_vulcanized_rubbers']
------------------------------------------------------------
Evaluating 4 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['plastic waste', 'municipal solid waste']
Resolving: plastic waste
directly matched: plastic waste
Resolved prediction: ['plastic waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['hydrogen', 'chemical', 'syngas']
Resolving: hydrogen
directly matched: hydrogen
Resolving: chemical
directly matched: chemical
Resolving: syngas
directly matched: syngas
Resolved prediction: ['hydrogen', 'chemical', 'syngas']
------------------------------------------------------------
Evaluating 5 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['lignocellulosic waste', 'pine sawdust', 'wheat straw']
Resolving: pine sawdust
directly matched: pine sawdust
Resolving: wheat straw
directly matched: wheat straw
Resolved prediction: ['pine sawdust', 'wheat straw']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['hydrolytic enzyme', 'cellulases', 'xylanases', '\u03b2-glucosidases']
Resolving: hydrolytic enzyme
directly matched: hydrolytic enzyme
Resolving: reducing sugar
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no. 

list: ['a: hydrolytic enzyme', 'b: cellulases', 'c: xylanases', 'd: \u03b2-glucosidases']. sample: reducing sugar.

answer: no.
Resolved prediction: ['hydrolytic enzyme', 'reducing sugar']
------------------------------------------------------------
Evaluating 6 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['plastic waste']
Resolving: plastic waste
directly matched: plastic waste
Resolving: hdpe
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['plastic waste', 'plastic waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['h2']
Resolving: h2
directly matched: h2
Resolved prediction: ['h2']
------------------------------------------------------------
Evaluating 7 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['biomass waste']
Resolving: biomass_waste
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['biomass waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['ethanol', 'acetaldehyde', 'hydrogen']
Resolving: ethanol
directly matched: ethanol
Resolving: acetaldehyde
directly matched: acetaldehyde
Resolving: hydrogen
directly matched: hydrogen
Resolved prediction: ['ethanol', 'acetaldehyde', 'hydrogen']
------------------------------------------------------------
Evaluating 8 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['digestate from anaerobic digestion of food waste']
Resolving: digestate
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['digestate from anaerobic digestion of food waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biochar', 'syngas', 'bio-oil']
Resolving: biochar
directly matched: biochar
Resolving: syngas
directly matched: syngas
Resolving: bio-oil
directly matched: bio-oil
Resolved prediction: ['biochar', 'syngas', 'bio-oil']
------------------------------------------------------------
Evaluating 9 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['agricultural waste metricals, residues and by-product', 'crop residue', 'straw', 'husk', 'shell', 'animal manure', 'food processing waste', 'forestry residue', 'microalgae']
Resolving: agricultural waste
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: microalgae
directly matched: microalgae
Resolving: energy crop
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolved prediction: ['agricultural waste metricals, residues and by-product', 'microalgae', 'crop residue']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biofuel', 'biochar for soil amendment']
Resolving: biofuel
directly matched: biofuel
Resolving: biochar
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolved prediction: ['biofuel', 'biochar for soil amendment']
------------------------------------------------------------
Evaluating 10 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['fish waste']
Resolving: fish waste
directly matched: fish waste
Resolved prediction: ['fish waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['vitamin d3 extract']
Resolving: 7-dehydrocholesterol
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['vitamin d3 extract']
------------------------------------------------------------
Evaluating 11 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['biowastes', 'coffee residue', 'bracts and peels of various fruit']
Resolving: coffee_residues
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolving: bracts_and_peels
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. c.
Resolved prediction: ['coffee residue', 'bracts and peels of various fruit']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['sorbent']
Resolving: cork
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: cotton
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: pollen
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: kapok
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: bamboo
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: sponge
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: algae
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: various_seeds
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['cork', 'sorbent', 'sorbent', 'sorbent', 'bamboo', 'sorbent', 'algae', 'various_seeds']
------------------------------------------------------------
Evaluating 12 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['sorghum waste']
Resolving: sorghum_waste
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['sorghum waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['sodium silicate', 'silica source for cr(vi) adsorbent synthesis']
Resolving: mi-cl-fdu-12
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a
Resolved prediction: ['sodium silicate']
------------------------------------------------------------
Evaluating 13 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['chestnut shell']
Resolving: chestnut_shells
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['chestnut shell']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['natural coloring agent', 'bioactive compound']
Resolving: natural_coloring_agents
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolving: bioactive_compounds
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolving: brown_melanin_like_pigments
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['bioactive compound', 'bioactive compound', 'natural coloring agent']
------------------------------------------------------------
Evaluating 14 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['lignocellulosic biomass', 'bio-waste material', 'agri-food waste']
Resolving: lignocellulosic_biomass
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: agri_food_wastes
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolved prediction: ['lignocellulosic biomass', 'bio-waste material']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['bioethanol', 'xylose']
Resolving: xylose
directly matched: xylose
Resolving: thermostable_ghs
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['xylose', 'thermostable_ghs']
------------------------------------------------------------
Evaluating 15 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['oil palm biomass', 'mill effluent']
Resolving: biomass
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: oil_palm_biomass
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: mill_effluent
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolved prediction: ['oil palm biomass', 'oil palm biomass', 'mill effluent']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biopolymer', 'graphene', 'biocomposites', 'mxene', 'biochemicals']
Resolving: biodiesel
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolving: bioethanol
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a
Resolving: biomethane
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: biohydrogen
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: bio_oil
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: jet_biofuel
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: biopolymer
directly matched: biopolymer
Resolving: graphene
directly matched: graphene
Resolving: biocomposites
directly matched: biocomposites
Resolving: mxene
directly matched: mxene
Resolving: biochemicals
directly matched: biochemicals
Resolved prediction: ['graphene', 'biopolymer', 'biomethane', 'biohydrogen', 'bio_oil', 'biopolymer', 'biopolymer', 'graphene', 'biocomposites', 'mxene', 'biochemicals']
------------------------------------------------------------
Evaluating 16 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['expanded polystyrene waste']
Resolving: expanded polystyrene waste
directly matched: expanded polystyrene waste
Resolved prediction: ['expanded polystyrene waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['superhydrophobic surfaces for food packaging']
Resolving: superhydrophobic surface
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['superhydrophobic surfaces for food packaging']
------------------------------------------------------------
Evaluating 17 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['face mask']
Resolving: face_mask
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['face mask']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['oil', 'fuel']
Resolving: oil
directly matched: oil
Resolved prediction: ['oil']
------------------------------------------------------------
Evaluating 18 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['waste products from chemical industry']
Resolving: waste_chemical_industry_material
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a
Resolved prediction: ['waste products from chemical industry']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['hollow concrete block', 'mortar', 'masonry unit']
Resolving: hollow_concrete_blocks
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a
Resolved prediction: ['hollow concrete block']
------------------------------------------------------------
Evaluating 19 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['waste polyethylene', 'plastic waste']
Resolving: waste_polyethylene
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['waste polyethylene']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['oil']
Resolving: pyrolysis_oil
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: light_fraction
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: aromatics
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['oil', 'oil', 'aromatics']
------------------------------------------------------------
Evaluating 20 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['cellulose-rich residue', 'food waste']
Resolving: cellulose-rich residue
directly matched: cellulose-rich residue
Resolved prediction: ['cellulose-rich residue']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['gelatin film', 'food packaging']
Resolving: gelatin film
directly matched: gelatin film
Resolving: sodium carboxymethyl cellulose
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['gelatin film', 'sodium carboxymethyl cellulose']
------------------------------------------------------------
Evaluating 21 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['bisphenol a']
Resolving: bisphenol a (bpa)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['bisphenol a']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biopolyol']
Resolving: 7,10-dihydroxy-8(e)-octadecenoic acid
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: extracellular diol synthase enzyme
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['7,10-dihydroxy-8(e)-octadecenoic acid', 'extracellular diol synthase enzyme']
------------------------------------------------------------
Evaluating 22 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['defatted apricot seed', 'oil-bearing biomass']
Resolving: defatted apricot seed
directly matched: defatted apricot seed
Resolved prediction: ['defatted apricot seed']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biochar']
Resolving: das biochars
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['biochar']
------------------------------------------------------------
Evaluating 23 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['molasses', 'corn steep liquor', 'black soldier fly larval meal']
Resolving: m2
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: ie
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: list: ['a: molasses', 'b: corn steep liquor', 'c: black soldier fly larval meal']. sample: ie.
answer: no.
Resolved prediction: ['m2', 'ie']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biobutanol', 'butanol']
Resolving: biobutanol
directly matched: biobutanol
Resolved prediction: ['biobutanol']
------------------------------------------------------------
Evaluating 24 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['biomass']
Resolving: biomass
directly matched: biomass
Resolving: waste
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['biomass', 'waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: []
Resolving: bio-oil
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: char
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: syngas
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['bio-oil', 'char', 'syngas']
------------------------------------------------------------
Evaluating 25 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['agro-industrial waste', 'biomass']
Resolving: agricultural_waste
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['agro-industrial waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['energy', 'chemical']
Resolving: biorefineries
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: high_value_added_products
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['energy', 'high_value_added_products']
------------------------------------------------------------
Evaluating 26 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['biowaste', 'crop residue', 'lignocellulosic biomass']
Resolving: biowaste
directly matched: biowaste
Resolving: lignin
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. c
Resolved prediction: ['biowaste', 'lignocellulosic biomass']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['phenolic compound', 'ferulic acid', 'vanillin', 'vanillic acid', 'hydroxycinnamic acid', 'food packaging']
Resolving: phenolic compound
directly matched: phenolic compound
Resolving: ferulic acid
directly matched: ferulic acid
Resolved prediction: ['phenolic compound', 'ferulic acid']
------------------------------------------------------------
Evaluating 27 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['waste polyethylene']
Resolving: polyethylene
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['waste polyethylene']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biosurfactants']
Resolving: alkane
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['alkane']
------------------------------------------------------------
Evaluating 28 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['grape pomace']
Resolving: grape_pomace
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['grape pomace']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['anthocyanins']
Resolving: anthocyanins
directly matched: anthocyanins
Resolved prediction: ['anthocyanins']
------------------------------------------------------------
Evaluating 29 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['waste cooking oil']
Resolving: waste cooking oil
directly matched: waste cooking oil
Resolved prediction: ['waste cooking oil']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biodiesel', 'light hydrocarbon', 'syngas', 'co', 'h2', 'liquid product', 'bioenergy and heat', 'animal feed']
Resolving: biodiesel
directly matched: biodiesel
Resolving: bioenergy
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. g.
Resolving: animal feed
directly matched: animal feed
Resolving: chemical feedstock
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolving: light hydrocarbons (c1 – c4)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolving: syngas (co and h2)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. c.
Resolving: liquid product
directly matched: liquid product
Resolved prediction: ['biodiesel', 'bioenergy and heat', 'animal feed', 'light hydrocarbon', 'light hydrocarbon', 'syngas', 'liquid product']
------------------------------------------------------------
Evaluating 30 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['combustible high-organic solid waste']
Resolving: high-organic solid waste (hsw)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['combustible high-organic solid waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['char']
Resolving: h-kaolin
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: oh-kaolin
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['h-kaolin', 'oh-kaolin']
------------------------------------------------------------
Evaluating 31 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['syngas']
Resolving: syngas
directly matched: syngas
Resolved prediction: ['syngas']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['hydrogen', 'polyhydroxyalkanoates']
Resolving: hydrogen
directly matched: hydrogen
Resolving: polyhydroxyalkanoates
directly matched: polyhydroxyalkanoates
Resolving: poly-3-hydroxybutyrate
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolved prediction: ['hydrogen', 'polyhydroxyalkanoates', 'polyhydroxyalkanoates']
------------------------------------------------------------
Evaluating 32 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['municipal solid waste incinerated fly ash']
Resolving: municipal solid waste incinerated fly ash
directly matched: municipal solid waste incinerated fly ash
Resolved prediction: ['municipal solid waste incinerated fly ash']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['substitute for m-sand in construction material', 'concrete tile']
Resolving: m-sand
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: mswifa-based concrete roof tile
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolved prediction: ['substitute for m-sand in construction material', 'concrete tile']
------------------------------------------------------------
Evaluating 33 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['fruit waste', 'vegetable waste']
Resolving: vegetable_waste
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolved prediction: ['vegetable waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['natural antioxidant', 'nutritional enhancement of oil']
Resolving: natural_antioxidants
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['natural antioxidant']
------------------------------------------------------------
Evaluating 34 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['agricultural residue', 'coconut husk']
Resolving: coconut husk
directly matched: coconut husk
Resolved prediction: ['coconut husk']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['syngas', 'carbon monoxide']
Resolving: syngas
directly matched: syngas
Resolving: bio-oil
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['syngas', 'bio-oil']
------------------------------------------------------------
Evaluating 35 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['synthetic wastewater', 'produced sludge']
Resolving: iron (iii) chloride
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: produced sludge
directly matched: produced sludge
Resolved prediction: ['iron (iii) chloride', 'produced sludge']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['recovered humic acid-free water']
Resolving: biochar/ferric chloride-based coagulant (bc–fecl3)
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: biochar
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['recovered humic acid-free water', 'biochar']
------------------------------------------------------------
Evaluating 36 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['thermal hydrolyzed sludge']
Resolving: thermal hydrolyzed sludge
directly matched: thermal hydrolyzed sludge
Resolved prediction: ['thermal hydrolyzed sludge']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['medium-chain fatty acid', 'n-caproate', 'n-caprylate']
Resolving: medium-chain fatty acid
directly matched: medium-chain fatty acid
Resolving: ethanol
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: acetate
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolved prediction: ['medium-chain fatty acid', 'ethanol', 'n-caproate']
------------------------------------------------------------
Evaluating 37 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['water treatment sludge']
Resolving: water treatment sludge
directly matched: water treatment sludge
Resolved prediction: ['water treatment sludge']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['sintering clay brick']
Resolving: structural sintering clay brick
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['sintering clay brick']
------------------------------------------------------------
Evaluating 38 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['waste activated sludge']
Resolving: waste activated sludge
directly matched: waste activated sludge
Resolved prediction: ['waste activated sludge']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['short-chain organic acid']
Resolving: short-chain organic acid
directly matched: short-chain organic acid
Resolving: acetic acid
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['short-chain organic acid', 'short-chain organic acid']
------------------------------------------------------------
Evaluating 39 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['industrial effluent']
Resolving: industrial effluent
directly matched: industrial effluent
Resolved prediction: ['industrial effluent']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['recovered water']
Resolving: pollutant
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['pollutant']
------------------------------------------------------------
Evaluating 40 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['urban wastewater']
Resolving: wastewater
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['urban wastewater']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['recovered water for algriculture', 'soil amender']
Resolving: algae
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: cyanobacterium desertifilum tharense berc-3
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['algae', 'cyanobacterium desertifilum tharense berc-3']
------------------------------------------------------------
Evaluating 41 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['dam sediment', 'marble waste']
Resolving: dam_sediments
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: marble_waste
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolved prediction: ['dam sediment', 'marble waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['road subgrade material']
Resolving: road_subgrade_materials
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['road subgrade material']
------------------------------------------------------------
Evaluating 42 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['nitrate pollutant']
Resolving: nitrate
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a
Resolved prediction: ['nitrate pollutant']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['ammonia', 'high-purity nh4cl']
Resolving: ammonia
directly matched: ammonia
Resolving: ammonium chloride
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolved prediction: ['ammonia', 'high-purity nh4cl']
------------------------------------------------------------
Evaluating 43 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['bio-sourced waste feedstock', 'agricultural corncob-derived biochar']
Resolving: biochar
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolved prediction: ['agricultural corncob-derived biochar']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biochar-based composite']
Resolving: bio-based composite
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['biochar-based composite']
------------------------------------------------------------
Evaluating 44 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['municipal solid waste']
Resolving: combustible fraction
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolved prediction: ['municipal solid waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['electrical energy']
Resolving: energy
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: ghg emission
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: electrical energy
directly matched: electrical energy
Resolved prediction: ['electrical energy', 'ghg emission', 'electrical energy']
------------------------------------------------------------
Evaluating 45 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['packaging', 'dross', 'incinerator bottom ash', 'salt-slag/salt-cake hazardous waste']
Resolving: aluminium waste
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolving: salt-slag
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. d.
Resolved prediction: ['aluminium waste', 'salt-slag/salt-cake hazardous waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['recyclable salt', 'aluminium concentrate', 'ammonium sulphate', 'non-metallic compounds (nmcs)', 'secondary cast aluminium alloy']
Resolving: secondary cast aluminium alloy
directly matched: secondary cast aluminium alloy
Resolving: recyclable salt
directly matched: recyclable salt
Resolving: aluminium concentrate
directly matched: aluminium concentrate
Resolving: ammonium sulphate
directly matched: ammonium sulphate
Resolving: non-metallic compounds (nmcs)
directly matched: non-metallic compounds (nmcs)
Resolved prediction: ['secondary cast aluminium alloy', 'recyclable salt', 'aluminium concentrate', 'ammonium sulphate', 'non-metallic compounds (nmcs)']
------------------------------------------------------------
Evaluating 46 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['lime sludge', 'lime slaker grit']
Resolving: lime_sludge
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: lime_slaker_grits
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. b.
Resolved prediction: ['lime sludge', 'lime slaker grit']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['magnesium oxysulfate-based fiber cement board']
Resolving: magnesium_oxysulfate_based_fiber_cement_boards
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a
Resolved prediction: ['magnesium oxysulfate-based fiber cement board']
------------------------------------------------------------
Evaluating 47 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['food waste', 'carrot pulp waste']
Resolving: carrot pulp waste
directly matched: carrot pulp waste
Resolved prediction: ['carrot pulp waste']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['fuel', 'chemical', 'syngas']
Resolving: syngas
directly matched: syngas
Resolving: bio-oil
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. c.
Resolved prediction: ['syngas', 'syngas']
------------------------------------------------------------
Evaluating 48 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['waste plastic', 'lignocellulosic biomass', 'rice straw']
Resolving: low-density polyethylene
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: rice straw
directly matched: rice straw
Resolving: waste plastic
directly matched: waste plastic
Resolving: lignocellulosic biomass
directly matched: lignocellulosic biomass
Resolved prediction: ['waste plastic', 'rice straw', 'waste plastic', 'lignocellulosic biomass']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['biogas', 'methane', 'biofuel']
Resolving: biogas
directly matched: biogas
Resolving: methane
directly matched: methane
Resolved prediction: ['biogas', 'methane']
------------------------------------------------------------
Evaluating 49 / 50
Using method: llm
Using model: llama3.1
Ground-truth list: ['incineration bottom ash']
Resolving: incineration bottom ash
directly matched: incineration bottom ash
Resolved prediction: ['incineration bottom ash']
------------------------------------------------------------
Using method: llm
Using model: llama3.1
Ground-truth list: ['natural aggregates substitutes for pavement layer']
Resolving: natural aggregate
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: treated iba
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: yes. a.
Resolving: iba with restriction
HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
use LLM, match_result: no.
Resolved prediction: ['natural aggregates substitutes for pavement layer', 'natural aggregates substitutes for pavement layer', 'iba with restriction']
------------------------------------------------------------
Total valid abstract: 50 / 50
Saved prediction result resolution to baseline_evaluation_1\prediction_resolution_llm.csv
Weighted micro precision: 0.8045977011494253, recall: 0.6896551724137931, f1: 0.7427055702917771
Weighted macro precision: 0.8449166666666668, recall: 0.7401666666666668, f1: 0.7608546453546452
Averaged jaccard: 0.6924166666666668
